[{"authors":null,"categories":null,"content":"I am a civil engineering graduate from Rashtreeya Vidyalaya College of Engineering. I care about all things geospatial and AI.\nI regularly write on Quora, tweet about FOSS, Deep Learning and my wild thoughts. When I\u0026rsquo;m not on my laptop, I\u0026rsquo;m usually seen in the park, jogging and playing badminton.\nMy Strengths include communication, adaptive learning and problem solving. I like keeping things clean, be it my code or my wardrobe.\n  Download my resum√©.\n","date":1583020800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1583020800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://amanbagrecha.github.io/author/aman-bagrecha/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/aman-bagrecha/","section":"authors","summary":"I am a civil engineering graduate from Rashtreeya Vidyalaya College of Engineering. I care about all things geospatial and AI.\nI regularly write on Quora, tweet about FOSS, Deep Learning and my wild thoughts.","tags":null,"title":"Aman Bagrecha","type":"authors"},{"authors":null,"categories":null,"content":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bb560906b6a99893cc21387348c0b074","permalink":"https://amanbagrecha.github.io/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Âê≥ÊÅ©ÈÅî","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  What you will learn Program overview Courses in this program Meet your instructor FAQs    What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program  Python basics Build a foundation in Python.   Visualization Learn how to visualize data with Plotly.   Statistics Introduction to statistics for data science.   Meet your instructor Aman Bagrecha FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://amanbagrecha.github.io/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"üìä Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz What is the difference between lists and tuples? Lists\n Lists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, 'Hello world']  Tuples\n Tuples are immutable - they can\u0026rsquo;t be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, 'Hello world')   Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"https://amanbagrecha.github.io/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n Write Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026quot;country == 'Canada'\u0026quot;) fig = px.bar(data_canada, x='year', y='pop') fig.show()  ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"https://amanbagrecha.github.io/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n  1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n The parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$.   Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"https://amanbagrecha.github.io/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":[],"categories":[],"content":"","date":1628614034,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628614034,"objectID":"f96f055b63d69d55b56d0cf41013faef","permalink":"https://amanbagrecha.github.io/project/geoserver-query/","publishdate":"2021-08-10T22:17:14+05:30","relpermalink":"/project/geoserver-query/","section":"project","summary":"This application demonstrates how to display and query all geoserver layers or from a workspace using geoserver REST API. CQL (Common Query Language) filter provided by geoserver is used to query the layer.","tags":["Django","postgis","geoserver","openlayers","webgis"],"title":"Openlayers Query via Geoserver","type":"project"},{"authors":[],"categories":[],"content":"","date":1627136816,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627136816,"objectID":"fb99a75e06489572990834469a04abfe","permalink":"https://amanbagrecha.github.io/project/ml_challenge/","publishdate":"2021-07-24T19:56:56+05:30","relpermalink":"/project/ml_challenge/","section":"project","summary":"The task at hand is to predict the age group of social media (app) users. Given the data of their users ranging from number of followers they have to hours they spend on the app, we are on the quest to solve what is the demography of the app.","tags":["datascience","python","pandas","matplotlib","sklearn"],"title":"Predicting Age group of Social Media Application users","type":"project"},{"authors":[],"categories":["QGIS"],"content":"Overview Most of the time, we are equipped with a discrete set of sample points (of temperature, rainfall etc) and are tasked with generating a continuous surface. This is where spatial interpolation comes into picture. The objective is to estimate the most probable value at an unknown location with a set of known points within the extent of sample points.\nMethods to perform spatial interpolation:\n  TIN: Triangular Irregular Network forms contiguous, non-overlapping triangles by dividing the geographic space on set of sample points\n  IDW: Inverse Distance Weighted interpolation method estimates cell values by weighted average of sample data. The closer the point, the more weight assigned. We can fix the radius of influence or the total sample points to weigh for cell value.\n  Spline: Also called french curves. It uses a mathematical function that minimizes overall surface curvature, resulting in a smooth surface that passes through the input points.\n  Kriging: A group of geostatistical techniques to interpolate the value of a random field at an unobserved location from observations of its value at a nearby location. It is implemented using semi-variogram.\n  In this blog, we create surface plots for Rainfall Correction Factors, which is indicative of how much the climate impacts a hydraulic structure based on the return period it is designed for.\nThese RCF are useful for hydraulic structures such as dams, storm water drains, and spillways. These RCF are derived from Global Climate Models (GCMs) which models future scenarios. Not considering these factors can lead to reduced life time of the structure.\nWe calculate the RCF for each point for a grid of lat,lon around the indian subcontinent. These RCF are as a result of intensive computational simulations run in matlab which is out of scope for this blog.\n1. Load points in QGIS Our data is in the csv format with each column of the RP_ family representing the return period the Rainfall Correction Factor is estimated for.\n\rFig.1 -sample data points with key location and return period of RCF\r\rThis file can be imported into qgis from the layers panel and adding a delimited text layer. Once the layer is added, we export as shapefile so as to ease the process of automating the workflow which comes in handy later at the end of the blog.\n\rFig.2 -Add the csv file using Add delimited text layer\r\rWe load the sampled points and add an India boundary as the base vector to later clip the features to our area of Interest.\n\rFig.3 -Points equally spaced around the Indian state. Each point represent a RCF value\r\r2. Generate Raster from points using TIN interpolation For demonstration let us take an example to run through the entire process of generating surface raster and styling which can be later automated using python in qgis.\nWe use these sampled locations of points to generate a surface using TIN Interpolation readily available as a toolbox in qgis. The input parameter for the vector layer is our shapefile of points while the interpolation attribute is going to be the RP_ family of columns.\n\rFig.4 -TIN interpolation in QGIS\r\rThe output of the interpolation with pixel size of 0.01 is shown below. The extent was set to the boundary of Indian state.\n\rFig.5 -Output surface raster with 0.01 pixel size\r\rWe can go a step further and derive contours using the contour toolbox provided in qgis.\n3. Generate Contours from raster to style the layer \rFig.6 -Generate contours from the surface raster\r\r\rFig.7 -Output as contour lines with 0.1 as interval\r\rA better way to get the contour lines is by changing the symbology of the raster to contours and providing an interval. This exact method will be employed later in this post.\nAutomating the process So far we have looked into creating surface raster for an individual return period. But we have several other return periods and we do not want to repeat ourselves. Thus we write a tiny python code to automate this workflow.\nWe derive the RCFs for return period of 5year, 10year, 25year, 50year\n# specify the output location for saving the files\rOUTPATH = 'D:\\\\gcm_qgis\\\\'\r# loop over different return periods from the shapefile\rfor i,j in enumerate(['2y', '10y', '25y', '50y'], 3):\r# specify the shapefile containing the RCP values\rMYFILE = 'D:\\\\gcm_qgis\\\\RCP_avg.shp|layername=RCP_avg::~::0::~::{}::~::0'.format(i)\r# Run interpolation and do not save the output permanently\rRESULTS = processing.run(\u0026quot;qgis:tininterpolation\u0026quot;, {'INTERPOLATION_DATA': MYFILE,\r'METHOD':1,\r'EXTENT':'68.205600900,97.395561000,6.755997100,37.084107000 [EPSG:4326]',\r'PIXEL_SIZE':0.01,\r'OUTPUT':'TEMPORARY_OUTPUT'})\r# clip the temporary output from prev step and save the files.\rprocessing.runAndLoadResults(\u0026quot;gdal:cliprasterbymasklayer\u0026quot;, {'INPUT':RESULTS['OUTPUT'],\r'MASK':'C:/Users/91911/Downloads/india-osm.geojson.txt|layername=india-osm.geojson',\r'SOURCE_CRS':None,'TARGET_CRS':None,'NODATA':None,\r'ALPHA_BAND':False,\r'CROP_TO_CUTLINE':True,\r'KEEP_RESOLUTION':False,'SET_RESOLUTION':False,'X_RESOLUTION':None,\r'Y_RESOLUTION':None,\r'MULTITHREADING':False,'OPTIONS':'',\r'DATA_TYPE':0,\r'EXTRA':'',\r'OUTPUT':os.path.join(OUTPATH, 'RCP_avg_' + j + '.tif')})\riface.messageBar().pushMessage(\r'Success:', 'Output file written at ', level=Qgis.Success)\r Our output would save and display the contour files with RCP_avg_{return_period} where return period ranges from [2,5,10,25,50]\nThe code first fetches our shapefile, which is used to\n create temporary TIN interpolation rasters clipped to india boundary using clip raster by mask layer  Once we have the rasters for each return period, we style the raster using singleband pseudocolor in Equal Interval mode ranging from 1.0 - 1.8 in steps of 0.1\nWe make a copy of the raster layer and place it above it, giving it a contour style at an interval of 0.1\nWe copy each return period and set the styling to be of contour as seen in the figure. This allows for a better visual representation of the regions with same the values.\n\rFig.8 -Styling the copy of surface raster\r\rThe final output can be seen in the below figure.\n\rFig.9 -Final output with contours overlaid on top of surface themself\r\rFinal comments We looked at various spatial interpolation technique and automated workflow to derive spatially interpolated surface raster.\nSources:\na. Comparison of Spatial Interpolation Techniques Using Visualization and Quantitative Assessment\nb. Spatial Analysis QGIS\n","date":1627084800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627144597,"objectID":"f235d6f7a57733bdf72415c7009b5d10","permalink":"https://amanbagrecha.github.io/post/qgis/contour-maps-in-qgis/","publishdate":"2021-07-24T00:00:00Z","relpermalink":"/post/qgis/contour-maps-in-qgis/","section":"post","summary":"Generate contour maps in QGIS and understand various interpolation methods.","tags":[],"title":"Contour Maps in QGIS","type":"post"},{"authors":[],"categories":["Geoserver","Openlayers"],"content":"Overview This blog demonstrates how to display and query all geoserver layers or from a workspace using geoserver REST API. CQL (Common Query Language) filter provided by geoserver is used to query the layer.\nWe create a full stack application, setting up the backend using django and the frontend using vanilla js. The application will later be deployed on aws ec2 instance.\nSetting up the backend (Django) Create virtual environment and activate it conda create --name djangoEnv\rconda activate djangoEnv\r Start a new project and create app django-admin startproject DOGP\rpython manage.py startapp gisapp\r Setup the database We set up postgresql for this exercise. Create a new database and add a postgis extension from it. For more info on how to set up the extension, click here.\nOnce the database is set up on the localhost server, we make changes to the settings.py module in our application.\n# change database\rDATABASES = {\r'default': {\r'ENGINE': 'django.contrib.gis.db.backends.postgis',\r'NAME': 'DOGP', # our new database name\r'USER': 'postgres',\r'PASSWORD': '1234',\r'HOST': '127.0.0.1',\r'PORT': '5432',\r},\r}\r Add installed apps \rINSTALLED_APPS = [\r'gisapp.apps.GisappConfig',\r'django.contrib.gis',\r]\r There are other setups such as setting up login page and authentication, creating media url root and setting up the url which we are not going to deal with in this blog post.\nOnce the setup is done, we run migrations to reflect those changes in the admin page.\nOn running python manage.py runserver you should see this page.\n\rFig.1 -Page indicating successful installation of Django\r\r Our focus will be on the frontend, but the full code can be accessed from here.\nFor querying and displaying layers from geoserver, we first need geoserver installed and running. For more info on how to do that can be found here.\nIn the following steps we setup our basemap layer to be ESRI World Imagery and define an empty vector layer to store the result of query.\n// map setup\rvar maplayer = new ol.layer.Tile({\rsource: new ol.source.XYZ({\rattributions: ['Powered by Esri','Source: Esri, DigitalGlobe, GeoEye, Earthstar Geographics, CNES/Airbus DS, USDA, USGS, AeroGRID, IGN, and the GIS User Community'],\rattributionsCollapsible: false,\rurl: 'https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\rmaxZoom: 23\r}),\rzIndex: 0\r})\rvar view = new ol.View({\rprojection: 'EPSG:4326',\rcenter: [-103.32989447589996, 44.18118547387081],\rzoom: 7,\r});\rvar map = new ol.Map({\rlayers: [ maplayer],\rtarget: 'map',\rview: view,\r});\r// define empty vector layer to store query result later\rvar SearchvectorLayerSource = new ol.source.Vector({\r})\rvar SearchvectorLayer = new ol.layer.Vector({\rsource:SearchvectorLayerSource\r});\rmap.addLayer(SearchvectorLayer);\r// define headers for authentication and login\rMyHeaders = {'Content-Type': 'application/json', 'Access-Control-Allow-Credentials' : true,\r'Access-Control-Allow-Origin':'*',\r'Accept': 'application/json',\r'Authorization': 'Basic ' + btoa('admin:geoserver')}\r To access all layers from a particular workspace, the api end point to do that is as follows\n// https://docs.geoserver.org/latest/en/api/#1.0.0/layers.yaml\r/workspaces/{workspaceName}/layers\r To see this in action, we display all layers from the sf workspace, provided in geoserver by default.\n\rFig.2 -Geoserver layers from sf workspace\r\rvar layerList = []; // array to store all the layer info\rvar loginInfo = [\u0026quot;admin\u0026quot;, \u0026quot;geoserver\u0026quot;]; // username and password for geoserver\rvar geoserverURL = geoserver_ip + \u0026quot;:\u0026quot; + geoserver_port // make ajax call to access the sf layer\r$.ajax({\rurl: geoserverURL + '/geoserver/rest/workspaces/sf/layers/',\rtype: 'GET',\rdataType: 'json',\rcontentType: \u0026quot;application/json\u0026quot;,\rbeforeSend: function(xhr) {\rxhr.setRequestHeader (\u0026quot;Authorization\u0026quot;, \u0026quot;Basic \u0026quot; + btoa(loginInfo[0] + \u0026quot;:\u0026quot; + loginInfo[1]));\r},\rsuccess: function(data){\rfor (var i = 0; i \u0026lt; data.layers.layer.length; i++) {\rlayerList.push([data.layers.layer[i].name, data.layers.layer[i].href]);\r}\r},\rasync: false\r});\r The output of this ajax call returns us a layerList array containing all the layer name and the url associated with it of size (:, 2)\nThis layer can then be displayed on the frontend by looping over the array and inserting into the div element.\n\rFig.3 -The layers of workspace `sf` displayed on the map with some styles applied to it\r\r\r The next step after displaying all the layers of the workspace is to load the features of the layer on selecting a particular layer.\nWhen the layer is ticked we send a request to geoserver to load the features of that layer and add to the map. If the layer is then unticked, we do the opposite and remove the layer from map.\nfunction toggleLayer(input) {\rif (input.checked) {\rwmsLayer = new ol.layer.Image({\rsource: new ol.source.ImageWMS({\rurl: geoserver_ip+ ':'+geoserver_port + \u0026quot;/geoserver/wms\u0026quot;,\rimageLoadFunction: tileLoader,\rparams: { LAYERS: input.value },\rserverType: \u0026quot;geoserver\u0026quot;,\r}),\rname: input.value,\r});\rmap.addLayer(wmsLayer);\r} else {\rmap.getLayers().forEach(layer =\u0026gt; {\rif (layer.get('name') == input.value) {\rmap.removeLayer(layer);\r}\r});\r}\r}\r \rFig.4 -Displaying layer on map\r\rQuery layer We start with the querying the layer by their attributes. We load all the attributes (as columns) and display as dropdown. We use wfs service and DescribeFeatureType request to load the attributes.\nfunction loadprops(layername) {\rselectedLayer = layername;\rfetch(\rgeoserver_ip+ ':'+geoserver_port+\u0026quot;/geoserver/wfs?service=wfs\u0026amp;version=2.0.0\u0026amp;request=DescribeFeatureType\u0026amp;typeNames=\u0026quot; + layername +\r\u0026quot;\u0026amp;outputFormat=application/json\u0026quot;,\r{\rmethod: \u0026quot;GET\u0026quot;,\rheaders: MyHeaders,\r}\r)\r.then(function (response) {\rreturn response.json();\r})\r.then(function (json) {\rvar allprops = json.featureTypes[0].properties;\rvar ColumnnamesSelect = document.getElementById(\u0026quot;Columnnames\u0026quot;);\rColumnnamesSelect.innerHTML = ''\rfor (i = 0; i \u0026lt; allprops.length; i++){\rif (allprops[i].name != 'the_geom') {\rColumnnamesSelect.innerHTML +=\r'\u0026lt;option value=\u0026quot;' +\rallprops[i].name +\r'\u0026quot;\u0026gt; ' +\rallprops[i].name +\r\u0026quot;\u0026lt;/option\u0026gt;\u0026quot;;\r}\r}\r});\r}\r Upto this point we have the layer and its features we want to search for. To query the layer we make a fetch call to ows service protocol and pass in the values of feature and the layer we want to query for.\nCQL_filter = column_name + \u0026quot; = '\u0026quot; + query_value + \u0026quot;'\u0026quot;;\rquery_url =geoserver_ip+ ':'+geoserver_port + \u0026quot;/geoserver/sf/ows?service=WFS\u0026amp;version=1.0.0\u0026amp;request=GetFeature\u0026amp;typeName=\u0026quot; + selectedLayer +\t\u0026quot;\u0026amp;CQL_FILTER=\u0026quot; +\tCQL_filter + \u0026quot;\u0026amp;outputFormat=application%2Fjson\u0026quot;;\rfetch_search_call(query_url).catch((error) =\u0026gt; {\rCQL_filter = column_name + \u0026quot;%20\u0026quot; + \u0026quot;ILIKE\u0026quot; + \u0026quot;%20%27%25\u0026quot; + query_value + \u0026quot;%25%27\u0026quot;;\r});\r We define a fetch_search_call function which makes a request to ows service and returns a geojson. We can parse the geojson and display it on the map.\nfunction fetch_search_call(query_url){\rfetch_result = fetch(query_url, {\rmethod: \u0026quot;GET\u0026quot;,\rheaders: MyHeaders,\r})\r.then(function (response) {\rreturn response.json();\r})\r.then(function (json) {\rSearchvectorLayerSource.clear()\rSearchvectorLayerSource.addFeatures(\rnew ol.format.GeoJSON({\r}).readFeatures(json)\r);\rif(json.features.length!=0){\r$('#searchModal').modal('toggle');\r}\rSearchvectorLayer.set('name','search_polygon_layer')\rmap.getView().fit(SearchvectorLayerSource.getExtent(), { duration: 1590, size: map.getSize(), padding: [10, 10, 13, 15], maxZoom:16});\rreturn fetch_result\r}\r The above function queries a feature and adds it to the map as a new layer. If the search is successful, we are zoomed into that location and only the feature queried gets displayed. If the fetch call could not find the match it returns an error which is caught by catch and displays the error to the client.\n\rFig.5 -Displaying Queried layer by attribute value\r\rThis completes the blog on how to query layer and display on the map. The working application can be viewed here.\n","date":1626393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626453841,"objectID":"a909fcac7f7bed099cbbb5483f4378fa","permalink":"https://amanbagrecha.github.io/post/geoserver/geoserver-query-builder/","publishdate":"2021-07-16T00:00:00Z","relpermalink":"/post/geoserver/geoserver-query-builder/","section":"post","summary":"This blog demonstrates how to display and query all geoserver layers or from a workspace using geoserver REST API. CQL (Common Query Language) filter provided by geoserver is used to query the layer.","tags":["geoserver","openlayers"],"title":"Query Geoserver Layer using openlayers","type":"post"},{"authors":[],"categories":[],"content":"","date":1626104573,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626104573,"objectID":"c1943345b169300789a0c72fd45f2bbb","permalink":"https://amanbagrecha.github.io/project/atharva/","publishdate":"2021-07-12T21:12:53+05:30","relpermalink":"/project/atharva/","section":"project","summary":"As part of concrete canoe competition representing team ASCE RVCE, the canoe hull was designed and analysed using SAP2000 and maxsurf","tags":["concrete","ASCE","other"],"title":"Structural Modelling and analysis of concrete canoe hull","type":"project"},{"authors":[],"categories":[],"content":"","date":1626100016,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626100016,"objectID":"ab313f5453707d43be90418519f196a6","permalink":"https://amanbagrecha.github.io/project/enrolmentbylevel/","publishdate":"2021-07-12T19:56:56+05:30","relpermalink":"/project/enrolmentbylevel/","section":"project","summary":"To evaluate the trend in higher education over the years based on gender, state, and degree program. Further identify which state requires additional university in the Indian State","tags":["datascience","python","pandas","matplotlib"],"title":"Analyse professional degree student enrolment v/s university count","type":"project"},{"authors":[],"categories":[],"content":"","date":1626100016,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626100016,"objectID":"f90dcc418ee30215edc19ba49e508e79","permalink":"https://amanbagrecha.github.io/project/land-surface-temperature/","publishdate":"2021-07-12T19:56:56+05:30","relpermalink":"/project/land-surface-temperature/","section":"project","summary":"Determining Land Surface Temperature of Bengaluru in ArcGIS using Landsat 8 product.","tags":["gis","arcgis","landsat"],"title":"Land Surface Temperature","type":"project"},{"authors":[],"categories":[],"content":"","date":1626100016,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626100016,"objectID":"3a8a05a93a402b87870fcae711a4dcaf","permalink":"https://amanbagrecha.github.io/project/spot-the-crop-radiantearth/","publishdate":"2021-07-12T19:56:56+05:30","relpermalink":"/project/spot-the-crop-radiantearth/","section":"project","summary":"Hackathon to classify crop type in south africa Based on time-series of Sentinel-1 satellite images. Stood at 5th place on public leaderboard.","tags":["datascience","python","pandas","matplotlib","sklearn"],"title":"Radiant Earth Spot the Crop Hackathon","type":"project"},{"authors":[],"categories":["Mapbox","Openlayers"],"content":"","date":1625720667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625720667,"objectID":"4bbcedaad20cd8012964be39a0bf11ba","permalink":"https://amanbagrecha.github.io/project/mapbox-api/","publishdate":"2021-07-08T10:34:27+05:30","relpermalink":"/project/mapbox-api/","section":"project","summary":"This Application demonstrates how to geocode an address using mapbox api implemented in openlayers v6. Additionally, on-click of search, the map gets zoomed to the location of Interest.","tags":["webgis","Openlayers","geocoding"],"title":"Geocoding using Mapbox API","type":"project"},{"authors":[],"categories":["python"],"content":"In this blog post we look into how to download precipitation data from NASA website. I show you two methods, one- directly reading the data using request module and preprocessing the file using pandas. Two- To download netCDF file using wget and using xarray to preprocess and visualise the data.\nWe will use xarray to preprocess the data and visualisation. We are going to work with GPM IMERG Late Precipitation L3 Half Hourly 0.1 degree x 0.1 degree V06 (GPM_3IMERGHHL) data provided by NASA which gives half-hourly precipitation values for entire globe.\nMethod 1: Using python to read on-the-fly and preprocess the data. Let us first look at one file which we need to read. Dataset: 3B-HHR.MS.MRG.3IMERG.20200502-S000000-E002959.0000.V06B.HDF5\rprecipitationCal[0][0], 0, 0, 0\rprecipitationCal[0][1], 0, 0, 0\rprecipitationCal[0][2], 0, 0, 0\rprecipitationCal[0][3], 0, 0, 0\rlat, 12.85, 12.95, 13.05\rlon, 77.45, 77.55, 77.65, 77.75\rtime, 1588377600\r As can be seen the first line contains information on satellite, start-time and date, end-time and date. It also lists the sensor on board the satellite. The second to fifth line lists the values for grid points. When selecting the subset from the NASA website, we choose a bounding box and here we see that we have 12 values: 4 rows and 3 columns. Each value is the centroid of the grid which spans 0.1 by 0.1 degree units. The the lat and lon rows are the centroid position on the map. The last row is the time since launch of the satellite in seconds.\nNote: we would need to have authorization in order to make GET request to the API. In google colab you need to first create .netrc file with credientials machine urs.earthdata.nasa.gov login your_login_username password your_password stored in the file. Then paste that file inside /root folder. Only then will you be authorised to fetch the data\nWe will be using google colab to process and read the file. The format we read in will be ASCII format.\nfrom google.colab import files\rimport pandas as pd\rimport numpy as np\rimport datetime\rimport re\rimport requests\r our subset.txt file looks like the following. df = pd.read_csv('/content/subset.txt', header=None, sep='\\n')[0] # dataframe to read the text file which contains all the download links\r_df = pd.DataFrame() # dataframe to store the result\rfor i in range(len(df)):\rurl = df[i] # reading the content of the file, line by line\rresult = requests.get(url)\rtry:\rresult.raise_for_status()\rf = result.content.decode(\u0026quot;utf-8\u0026quot;).splitlines() # decode the content recieved and split the line\rdate_str = re.findall('3IMERG.(.*?)-', f[0])[0] #yyyymmdd use regex to find the date str in `3B-HHR.MS.MRG.3IMERG.20200502-S000000-E002959.0000.V06B.HDF5`\rtime_str = re.findall('-S(.*?)-', f[0])[0] #HHMMSS use regex to find the time str in `3B-HHR.MS.MRG.3IMERG.20200502-S000000-E002959.0000.V06B.HDF5`\rdate_obj = datetime.datetime.strptime(date_str, '%Y%m%d').date() # convert the date str to date object\rtime_obj = datetime.datetime.strptime(time_str, '%H%M%S').time() # convert the time str to time object\rl1 = list(map(func1, f)) # map the content of the file by func1 and convert to list l2= list(map(func2, l1[1:4])) # # map the content of the file by func2 and convert to list avg = sum(l2)/len(l2) # take avg of all the resulting precipitation value\r_df.loc[date_obj, time_obj] = avg\rexcept:\rprint('requests.get() returned an error code '+str(result.status_code))\r_df.to_csv('output.csv')\r In the above snippet, we first read the file using request module and decode the content. We use regex to find the match (in our case to find the precipitation value) and convert to date-time objects. Then, we take the average of all the values (precipitation) and store in a new dataframe. This dataframe will be our final product having date_obj number of rows and time_obj number of columns. The functions func1 and func2 are used here to calculate the average rainfall in mm/hr for half-hourly period.\n# we split the string on comma and extract the precipitation value alone\rdef func1(f):\rreturn f.split(',')[-2:]\r# we take the sum of the all the precipitation value which will be later used to take the average across all the ROI\rdef func2(f):\rreturn sum(list(map(float, f)))\r At this stage all the files are read and the dataframe can now be exported to csv. Our csv looks like the following. Method 2: Using wget to download and then preprocess using xarray (simple and easy) We first download all files using wget having stored all the urls stored in a text file. These files are then read using xarray which makes it really easy to process and get the information we require. We first run shell command inside colab.\n! wget --load-cookies /.urs_cookies --save-cookies /root/.urs_cookies --auth-no-challenge=on --user=your_user_name --ask-password --content-disposition -i \u0026lt;url text file\u0026gt;\r import xarray as xr\rimport glob\rds = xr.merge([xr.open_dataset(f) for f in glob.glob('/content/*.nc4')]) # merge all the netcdf files into a single xarray dataset\rds1.precipitationCal.mean(dim=('lon', 'lat')).plot() # calculate the average precipitation on half-hourly basis.\r At this stage we have the data preprocessed and is now ready to be used for various modelling and analysis phase.\nFinal Comments In this tech-blog we looked into how to download and preprocess netCDF data provided by NASA GES DISC. We looked at two methods, one with request and pandas while the other with wget and xarray. All performed on google colab. It is to note that, there is setup required i.e, to create a new .netrc file and store inside root directory of colab else it returns an authorisation error. We looked at how easy it is to process netCDF data in xarray and how wget command can be run on colab.\n Data courtesy: Huffman, G.J., E.F. Stocker, D.T. Bolvin, E.J. Nelkin, Jackson Tan (2019), GPM IMERG Late Precipitation L3 Half Hourly 0.1 degree x 0.1 degree V06, Greenbelt, MD, Goddard Earth Sciences Data and Information Services Center (GES DISC), Accessed: [Data Access Date], 10.5067/GPM/IMERG/3B-HH-L/06\n ","date":1623283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623341005,"objectID":"f149a5d405f6a8e7107a6f885ad432c0","permalink":"https://amanbagrecha.github.io/post/xarray/download-and-preprocess-nasa-gpm-imerg-data-using-python-and-wget/","publishdate":"2021-06-10T00:00:00Z","relpermalink":"/post/xarray/download-and-preprocess-nasa-gpm-imerg-data-using-python-and-wget/","section":"post","summary":"In this blog post we look into how to download precipitation data from NASA website and process it with `xarray` and `wget`.","tags":["xarray","colab"],"title":"Download and preprocess NASA GPM IMERG Data using python and wget","type":"post"},{"authors":[],"categories":["QGIS","machine learning"],"content":"The problem statement Any land-use land cover classification needs to be validated with ground-truth data to measure the accuracy. A key single-valued statistic to determine the effectiveness of classification is Cohen‚Äôs kappa. This validation metric has been fairly widely used for unbalanced classification as well which expresses a level of agreement between two annotators on a classification problem.\nThe objective of this quality assessment was to validate the land cover map performed on June, 2020 sentinel-2 imagery by k-means classification algorithm, thus providing a statistical measure of overall class predictions. The validation was done using an independent set of sample points (~500) generated randomly following stratified random sampling design, to capture the variance within the class\nAfter running the tool, the sample points were manually assigned to the ground-truth class. The ground-truth dataset was taken to be Bing-satellite imagery as a proxy for field data. Each sample point was labelled by visual inspection on the ground-truth dataset.\nStep 1: Classify Image  Load raster Image Open K-means clustering for grids under SAGA tools. Select the raster Image as grid and in this case we specify 4 classes  \rFig.1 -K-means clustering on sentinel-2 Image\r\r Click Run   At this stage we have unsupervised k-means clustering output ready (Fig.2).\n \rFig.2 -classification of RR Nagar, Bengaluru. Classes- Forest, Urban, water, Bareland\r\r Step 2: Convert to polygon (vector format)  Select Polygonize (Raster to Vector) tool under GDAL-\u0026gt;Raster Conversion Select the classified image as input. Leave everything else as default. The output would be a Vectorised scratch layer.  \rFig.3 -Convert Raster to vector\r\r Note the name of the field (DN here). This will be used later.\n  Fix geometries (this step is important here to avoid any error in further steps) Vector Geometry-\u0026gt;Fix Geometry  \rFig.4 -Fixing topology issues with Fix Geometry Toolbox\r\r Step 3: Dissolve the layer on DN field In this step we dissolve the layer based on the DN value. This will ensure that each polygon can be evaluated based on the land class type which is needed for stratified random sampling.\n\rFig.5 -Dissolve toolbox to dissolve polygon on  DN  value\r\r Make sure to select dissolve field as DN\n  Step 4: Create stratified random samples Go to Vector-\u0026gt;research tools-\u0026gt; Random Points inside Polygon and set Sampling Strategy = Points Density and Point count or density = 0.001.\nNote: The value 0.001 signify 1 point for 1/0.001 m2 of area, given that the units is meters.\n\rFig.6 - One sample point is generated for each 1000 m2 of area\r\r Step 5: Extract raster values to sample layer We extract the raster value, which is essentially the land cover class for the classified image. We use Sample Raster Values function here (Fig.7). The input layer is the random points we generated earlier and the the raster layer is the classified image. The output adds a new column to the sample points layer with the prediction class of the land-cover (Fig.8).\n\rFig.7 -Running Sample Raster Value to extract Raster values for the input points\r\r\rFig.8 -The corresponding Attribute Table with Predicted Class  PREDICTED_1 for each feature\r\r Step 6: Ground Truth Labelling using Bing maps At this stage we are ready to validate the image using Bing maps as ground truth. We turn on the edit mode and create new field named Actual class. THen we visually inspect the class on the map and note the land-cover class. Once we inspect all the sample points we can use cohens Kappa statistics to determine the validation result. Alternatively, simply calculating the accuracy would also suffice the need.\nStep 7: Add other field to the attribute table with reclassification We can use the Field Calculator to generate verbose text for each label in our feature class and display labels for the prediction.\n-- in field calculator to increase verbosity\rCASE WHEN PREDICTED_1 is 2 THEN 'Urban' WHEN PREDICTED_1 is 1 THEN 'Bareland'\rWHEN PREDICTED_1 is 4 THEN 'Forest'\rWHEN PREDICTED_1 is 3 THEN 'Urban'\rEND\r \rFig.9 -Predicted classes (foreground) vs ground truth (background)\r\rWith this we come to end of the post. Now, validation accuracy can be reported for k-means classification.\n","date":1623196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623066166,"objectID":"3a45a2ad16d50fc70c8522d1f84ada9f","permalink":"https://amanbagrecha.github.io/post/qgis/validating-lulc-classes-in-qgis/","publishdate":"2021-06-09T00:00:00Z","relpermalink":"/post/qgis/validating-lulc-classes-in-qgis/","section":"post","summary":"The objective of this quality assessment was to validate the land cover map performed on June, 2020 sentinel-2 imagery by k-means classification algorithm in QGIS","tags":["qgis","machine learning"],"title":"Validating LULC classes in QGIS","type":"post"},{"authors":[],"categories":["openlayers","Mapbox"],"content":"Overview The big picture of this post can be related to google maps, wherein you type the address and it zooms in to the location of interest. We replicate this exact functionality with mapbox API for geocoding and openlayers for client side zoom to the address of interest.\nMain steps This blog demonstrates how to geocode an address using mapbox api implemented in openlayers v6. Additionally zoom in to the search location as text provided on the search bar. This one page appication demostrates only key elements, rest of the customisation is at discretion of the viewer.\nSetup the project We first create basic single html file to include all elements (javascript, css and html). Ideally, when the application scales, you would create a seperate file for each component.\n Create html file and add basic elements  \u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt;\r\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://cdn.jsdelivr.net/gh/openlayers/openlayers.github.io@master/en/v6.5.0/css/ol.css\u0026quot; type=\u0026quot;text/css\u0026quot;\u0026gt;\r\u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt;\r.autocomplete {\rposition: relative;\rdisplay: inline-block;\r}\rinput {\rborder: 1px solid transparent;\rbackground-color: #f1f1f1;\rpadding: 10px;\rfont-size: 16px;\r}\rinput[type=text] {\rbackground-color: #f1f1f1;\rwidth: 100%;\r}\rinput[type=submit] {\rbackground-color: DodgerBlue;\rcolor: #fff;\rcursor: pointer;\r}\r\u0026lt;/style\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;!--create search bar for geocoding and style it --\u0026gt;\r\u0026lt;h2\u0026gt;Autocomplete\u0026lt;/h2\u0026gt;\r\u0026lt;br\u0026gt;\r\u0026lt;form method=\u0026quot;post\u0026quot; \u0026gt;\r\u0026lt;div class=\u0026quot;autocomplete\u0026quot; style=\u0026quot;width:300px;\u0026quot;\u0026gt;\r\u0026lt;input id=\u0026quot;myInput\u0026quot; type=\u0026quot;text\u0026quot; name=\u0026quot;myCountry\u0026quot; placeholder=\u0026quot;Country\u0026quot;\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;input type=\u0026quot;submit\u0026quot; id = \u0026quot;geocodingSubmit\u0026quot;\u0026gt;\r\u0026lt;/form\u0026gt;\r\u0026lt;div id='project_map', class=\u0026quot;map\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/gh/openlayers/openlayers.github.io@master/en/v6.5.0/build/ol.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;!-- \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/proj4js/2.5.0/proj4.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; --\u0026gt;\r\u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt;\r// create basemap layer\rvar project_maplayer = new ol.layer.Tile({\r// source: new ol.source.OSM(),\rsource: new ol.source.XYZ({\rattributions: ['Powered by Esri',\r'Source: Esri, DigitalGlobe, GeoEye, Earthstar Geographics, CNES/Airbus DS, USDA, USGS, AeroGRID, IGN, and the GIS User Community'],\rattributionsCollapsible: false,\rurl: 'https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\rmaxZoom: 23\r}),\rzIndex: 0\r});\r// create view for the layer\rvar project_view = new ol.View({\rprojection: 'EPSG:4326',\rcenter: [-81.80808208706726, 27.285095000261222],\rzoom: 7,\r});\r// add the basemap to the map\rvar Projectmap = new ol.Map({\rlayers: [project_maplayer,],\rtarget: 'project_map',\rview: project_view,\rconstrainOnlyCenter: true,\r});\r\u0026lt;/script\u0026gt;\r We added the following elements,\n Search bar: we setup the search function to input values as address and wrap it within a form with post request. Map : the div element with id=\u0026quot;project_map\u0026quot; holds the map element and the script does the following. First, create layer with ESRI basemap. Second, add the layer to the Map object.  At this stage the application looks like the following image\nAdd autocomplete functionality We fetch from the api and populate our top results in a list format on key press. Also, we style the search bar using css.\n\u0026lt;style\u0026gt;\r.autocomplete-items {\rposition: absolute;\rborder: 1px solid #d4d4d4;\rborder-bottom: none;\rborder-top: none;\rz-index: 99;\r/*position the autocomplete items to be the same width as the container:*/\rtop: 100%;\rleft: 0;\rright: 0;\r}\r.autocomplete-items div {\rpadding: 10px;\rcursor: pointer;\rbackground-color: #fff; border-bottom: 1px solid #d4d4d4; }\r/*when hovering an item:*/\r.autocomplete-items div:hover {\rbackground-color: #e9e9e9; }\r/*when navigating through the items using the arrow keys:*/\r.autocomplete-active {\rbackground-color: DodgerBlue !important; color: #ffffff; }\r\u0026lt;/style\u0026gt;\r\u0026lt;script\u0026gt;\rmyHeaders = {'Content-Type': 'application/json', 'Access-Control-Allow-Credentials' : true,\r'Access-Control-Allow-Origin':'*',\r'Accept': 'application/json'}\rfunction autocomplete(inp) {\r/*the autocomplete function takes one argument,\rthe text field element*/\rvar currentFocus;\r/*execute a function when someone writes in the text field:*/\rinp.addEventListener(\u0026quot;input\u0026quot;, function(e) {\rvar a, b, i, val = this.value;\rvar ACCESS_TOKEN_KEY = 'your_token_here'\r/*close any already open lists of autocompleted values*/\rvar URL = `https://api.mapbox.com/geocoding/v5/mapbox.places/${val}.json?access_token=${ACCESS_TOKEN_KEY}\u0026amp;types=address,region,poi,country,district,locality,neighborhood,postcode\u0026amp;country=us`\rfetch(URL,{\rmethod: 'GET',\rheaders: myHeaders,\r}).then(response =\u0026gt; response.json())\r.then(data =\u0026gt; {\rgeocode_data = data;\r// console.log(data) closeAllLists();\rif (!val) { return false;}\rcurrentFocus = -1;\r/*create a DIV element that will contain the items (values):*/\ra = document.createElement(\u0026quot;DIV\u0026quot;);\ra.setAttribute(\u0026quot;id\u0026quot;, this.id + \u0026quot;autocomplete-list\u0026quot;);\ra.setAttribute(\u0026quot;class\u0026quot;, \u0026quot;autocomplete-items\u0026quot;);\r/*append the DIV element as a child of the autocomplete container:*/\rthis.parentNode.appendChild(a);\r/*for each item in the array...*/\rfor (i = 0; i \u0026lt; geocode_data.features.length; i++) {\rb = document.createElement(\u0026quot;DIV\u0026quot;);\r/*insert a input field that will hold the current array item's value:*/\rb.innerHTML += geocode_data.features[i].place_name;\rb.innerHTML += `\u0026lt;input type='hidden' style=\u0026quot;display: none;\u0026quot; id=${i}-center-cc coordinates='${geocode_data.features[i].center}' value='${geocode_data.features[i].place_name}'\u0026gt;`;\r/*execute a function when someone clicks on the item value (DIV element):*/\rb.addEventListener(\u0026quot;click\u0026quot;, function(e) {\r/*insert the value for the autocomplete text field:*/\rvar input_tag = this.getElementsByTagName(\u0026quot;input\u0026quot;)[0]\rinp.value = input_tag.value;\rinp.setAttribute(\u0026quot;coordinates\u0026quot;, input_tag.getAttribute('coordinates'));\r/*close the list of autocompleted values,\r(or any other open lists of autocompleted values:*/\rcloseAllLists();\r});\ra.appendChild(b);\r}\r})\r.catch(error =\u0026gt; {\rconsole.error('There has been a problem with your fetch operation:', error);\r});\r});\r// });\r/*execute a function presses a key on the keyboard:*/\rinp.addEventListener(\u0026quot;keydown\u0026quot;, function(e) {\rvar x = document.getElementById(this.id + \u0026quot;autocomplete-list\u0026quot;);\rif (x) x = x.getElementsByTagName(\u0026quot;div\u0026quot;);\rif (e.keyCode == 40) {\r/*If the arrow DOWN key is pressed,\rincrease the currentFocus variable:*/\rcurrentFocus++;\r/*and and make the current item more visible:*/\raddActive(x);\r} else if (e.keyCode == 38) { //up\r/*If the arrow UP key is pressed,\rdecrease the currentFocus variable:*/\rcurrentFocus--;\r/*and and make the current item more visible:*/\raddActive(x);\r} else if (e.keyCode == 13) {\r/*If the ENTER key is pressed, prevent the form from being submitted,*/\re.preventDefault();\rif (currentFocus \u0026gt; -1) {\r/*and simulate a click on the \u0026quot;active\u0026quot; item:*/\rif (x) x[currentFocus].click();\r}\r}\r});\rfunction addActive(x) {\r/*a function to classify an item as \u0026quot;active\u0026quot;:*/\rif (!x) return false;\r/*start by removing the \u0026quot;active\u0026quot; class on all items:*/\rremoveActive(x);\rif (currentFocus \u0026gt;= x.length) currentFocus = 0;\rif (currentFocus \u0026lt; 0) currentFocus = (x.length - 1);\r/*add class \u0026quot;autocomplete-active\u0026quot;:*/\rx[currentFocus].classList.add(\u0026quot;autocomplete-active\u0026quot;);\r}\rfunction removeActive(x) {\r/*a function to remove the \u0026quot;active\u0026quot; class from all autocomplete items:*/\rfor (var i = 0; i \u0026lt; x.length; i++) {\rx[i].classList.remove(\u0026quot;autocomplete-active\u0026quot;);\r}\r}\rfunction closeAllLists(elmnt) {\r/*close all autocomplete lists in the document,\rexcept the one passed as an argument:*/\rvar x = document.getElementsByClassName(\u0026quot;autocomplete-items\u0026quot;);\rfor (var i = 0; i \u0026lt; x.length; i++) {\rif (elmnt != x[i] \u0026amp;\u0026amp; elmnt != inp) {\rx[i].parentNode.removeChild(x[i]);\r}\r}\r}\r/*execute a function when someone clicks in the document:*/\rdocument.addEventListener(\u0026quot;click\u0026quot;, function (e) {\rcloseAllLists(e.target);\r});\r}\r/*initiate the autocomplete function on the \u0026quot;myInput\u0026quot; element */\rautocomplete(document.getElementById(\u0026quot;myInput\u0026quot;));\r\u0026lt;/script\u0026gt;\r The following is the explanation of the code\n autocomplete function: The function takes an element as input which needs to be populated. Then we add an event listner which on change in input field, triggers. A GET request is sent across for the input typed and the result is populated in a form of dropdown. We add some styling on key-down so as to select the search.  At this point, with correct mapbox api access key, we have built the autocomplete functionality.\nLast steps We now only need to implement the submit functionality. On click of submit button, the address is located on the map and zoomed in. This is done using a function we call centerMap\nfunction CenterMap() {\rvar [long, lat] = document.getElementById(\u0026quot;myInput\u0026quot;).getAttribute(\u0026quot;coordinates\u0026quot;).split(\u0026quot;,\u0026quot;).map(Number)\rconsole.log(\u0026quot;Long: \u0026quot; + long + \u0026quot; Lat: \u0026quot; + lat);\rProjectmap.getView().setCenter(ol.proj.transform([long, lat], 'EPSG:4326', 'EPSG:4326'));\rProjectmap.getView().setZoom(5);\r}\r Now we add the centerMap function on click of submit\ndocument.getElementById(\u0026quot;geocodingSubmit\u0026quot;).addEventListener('click', function(e){\re.preventDefault();\rCenterMap()\r})\r The associated running application can be found here\n","date":1621866893,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621866893,"objectID":"f3c3e376bc0dde891d19e2b7fea666e6","permalink":"https://amanbagrecha.github.io/post/openlayers/geocode-using-mapbox-api-with-zoom-functionality/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/openlayers/geocode-using-mapbox-api-with-zoom-functionality/","section":"post","summary":"How to bulid geocoding web-app using openlayers","tags":[],"title":"Geocoding using Mapbox API with Zoom-in map functionality","type":"post"},{"authors":[],"categories":["Django"],"content":"Overview In this post, we look into how to upload multiple geo-tagged/non-geotagged images to aws s3 using plain Django and spatialite as databbase. We use GeoDjango to store the latitude, longitude extracted from geo-tagged images into the database.\n\rProject setup create django project\ndjango-admin startproject login_boiler_plate\rcreate app python manage.py startapp GisMap\rcreate superuser python manage.py createsuperuser\r In settings.py add the app to installed_app list and setup the default location for media storage.\nINSTALLED_APPS = [\r...\r'GisMap',\r]\rMEDIA_ROOT = os.path.join(BASE_DIR, 'media') MEDIA_URL = '/media/'\r Setup the database backend to postgis extenstion of postgresql. # in settings.py file\rDATABASES = {\r'default': {\r'ENGINE': 'django.contrib.gis.db.backends.postgis', #imp\r'NAME': 'database_name_here',\r'USER': 'postgres',\r'PASSWORD': 'password_here',\r'HOST': 'localhost',\r'PORT': '5432',\r},\r}\r In models.py, create model for uploading images. DateTimeField and user are not necessary.\nfrom django.db import models\rfrom django.contrib.auth.models import User\rclass ImageUpload(models.Model):\ruser = models.ForeignKey(User, null=True, on_delete=models.CASCADE)\rimage = models.ImageField( null=False, blank=False, upload_to = 'images/')\rdate_created = models.DateTimeField(auto_now_add=True, null=True)\rdef __str__(self):\rreturn self.user.username + \u0026quot; uploaded: \u0026quot;+ self.image.name\r In forms.py, refer to the ImageUpload model for input.\nfrom django.forms import ModelForm\rfrom django.contrib.auth.models import User\rfrom .models import ImageUpload\rclass ImageForm(ModelForm):\rclass Meta:\rmodel = ImageUpload\rfields = ('image',)\r In home.html, create the form to accept image upload.\n\u0026lt;!-- Modal --\u0026gt;\r\u0026lt;form method = \u0026quot;post\u0026quot; enctype=\u0026quot;multipart/form-data\u0026quot;\u0026gt;\r\u0026lt;div class=\u0026quot;modal fade\u0026quot; id=\u0026quot;exampleModal\u0026quot; tabindex=\u0026quot;-1\u0026quot; role=\u0026quot;dialog\u0026quot; aria-labelledby=\u0026quot;exampleModalLabel\u0026quot; aria-hidden=\u0026quot;true\u0026quot; \u0026gt;\r{% csrf_token %}\r\u0026lt;div class=\u0026quot;modal-dialog\u0026quot; role=\u0026quot;document\u0026quot;\u0026gt;\r\u0026lt;div class=\u0026quot;modal-content\u0026quot;\u0026gt;\r\u0026lt;div class=\u0026quot;modal-header\u0026quot;\u0026gt;\r\u0026lt;h5 class=\u0026quot;modal-title\u0026quot; id=\u0026quot;exampleModalLabel\u0026quot;\u0026gt;Upload Image\u0026lt;/h5\u0026gt;\r\u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;modal\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt;\r\u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt;\r\u0026lt;/button\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;div class=\u0026quot;modal-body\u0026quot;\u0026gt;\r{{ image_form.image }}\r\u0026lt;/div\u0026gt;\r\u0026lt;div class=\u0026quot;modal-footer\u0026quot;\u0026gt;\r\u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;btn btn-secondary\u0026quot; data-dismiss=\u0026quot;modal\u0026quot;\u0026gt;Close\u0026lt;/button\u0026gt;\r\u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Save Image\u0026lt;/button\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/form\u0026gt;\r In views.py, accept the HTTP POST request and save to the database. We will alter this to extract latitude, longitude later.\n@login_required(login_url='login')\rdef home_page(request):\rif request.method == 'POST':\rform = ImageForm(request.POST , request.FILES)\rprint(form)\rif form.is_valid():\rprint(\u0026quot;is valid\u0026quot;)\robj = form.save(commit=False)\robj.user = request.user\robj.save()\rreturn redirect('home')\relse:\rImageform = ImageForm()\rreturn render(request, \u0026quot;GisMap/home.html\u0026quot;, {'Title': \u0026quot;Home Page\u0026quot;, \u0026quot;image_form\u0026quot;: ImageForm})\r Get Lat, lon from image meta deta (Exchangeable image file format [EXIF] )  Geodjango is built on top of django and adds spatial functionality such as storing points, lines , polygon and multipolygon. It is prepackaged with Django but requires few additional softwares to make it fully functional. These include- GDAL, PROJ, GEOS, PostGIS. These can be downloaded from osgeo4W which bundles all these libraries. Then application can be added to apps in settings with django.contrib.gis to the installed apps.  By default geodjango is not installed in the apps list and thus we do it ourself.\npip install django-geo\r NOTE- ensure os4geo is installed: install from here if not done. And make the following changes in settings.py.\nAn additional setting is required, which is to locate osgeo4w directory in django. If you install osgeo4w in default directory, you need to put the following code within the settings.py file.\nINSTALLED_APPS = [\r...\r'django.contrib.gis',\r]\rimport os\rimport posixpath\rif os.name == 'nt':\rimport platform\rOSGEO4W = r\u0026quot;C:\\OSGeo4W\u0026quot;\rif '64' in platform.architecture()[0]:\rOSGEO4W += \u0026quot;64\u0026quot;\rassert os.path.isdir(OSGEO4W), \u0026quot;Directory does not exist: \u0026quot; + OSGEO4W\ros.environ['OSGEO4W_ROOT'] = OSGEO4W\ros.environ['GDAL_DATA'] = OSGEO4W + r\u0026quot;\\share\\gdal\u0026quot;\ros.environ['PROJ_LIB'] = OSGEO4W + r\u0026quot;\\share\\proj\u0026quot;\ros.environ['PATH'] = OSGEO4W + r\u0026quot;\\bin;\u0026quot; + os.environ['PATH']\r In models.py, add a PointField which can store geospatial information (lat,lon)\nfrom django.contrib.gis.db import models\rclass ImageUpload():\r... geom = models.PointField( null=True)\r In views.py, define functions to extract meta data from image and convert into right format for GeoDjango to understand it. Courtesy of Jayson DeLancey\n#________________________________________FUNCTIONS FOR IMAGE EXIF DATA______________________________________________________________________________#\rfrom PIL import Image\rfrom urllib.request import urlopen\rfrom PIL.ExifTags import GPSTAGS\rfrom PIL.ExifTags import TAGS\rdef get_decimal_from_dms(dms, ref):\rdegrees = dms[0]\rminutes = dms[1] / 60.0\rseconds = dms[2] / 3600.0\rif ref in ['S', 'W']:\rdegrees = -degrees\rminutes = -minutes\rseconds = -seconds\rreturn round(degrees + minutes + seconds, 5)\rdef get_coordinates(geotags):\rlat = get_decimal_from_dms(geotags['GPSLatitude'], geotags['GPSLatitudeRef'])\rlon = get_decimal_from_dms(geotags['GPSLongitude'], geotags['GPSLongitudeRef'])\rreturn (lon, lat)\rdef get_geotagging(exif):\rif not exif:\rraise ValueError(\u0026quot;No EXIF metadata found\u0026quot;)\rgeotagging = {}\rfor (idx, tag) in TAGS.items():\rif tag == 'GPSInfo':\rif idx not in exif:\rraise ValueError(\u0026quot;No EXIF geotagging found\u0026quot;)\rfor (key, val) in GPSTAGS.items():\rif key in exif[idx]:\rgeotagging[val] = exif[idx][key]\rreturn geotagging\r#_______________________________________________________________________________________________________________________________________#\r In views.py, update home_page function to extract meta data and save the image to database.\nfrom django.contrib.gis.geos import Point\r@login_required(login_url='login')\rdef home_page(request):\rif request.method == \u0026quot;POST\u0026quot;:\rform = ImageForm(request.POST, request.FILES)\rimg = Image.open(request.FILES.get(\u0026quot;image\u0026quot;))\rif form.is_valid():\rtry:\robj = form.save(commit=False)\robj.user = request.user\robj.image_url = obj.image.url\rgeotags = get_geotagging(img._getexif())\robj.geom = Point(\rget_coordinates(geotags)\r) # X is longitude, Y is latitude, Point(X,Y)\robj.save()\rmessages.success(request, f\u0026quot;image uploaded succesfully\u0026quot;)\rexcept ValueError as e:\rmessages.warning(request, e)\relse:\rmessages.warning(request, f\u0026quot;Invalid image type\u0026quot;)\rreturn redirect(\u0026quot;home\u0026quot;)\relse:\rImageform = ImageForm()\rreturn render(\rrequest, \u0026quot;GisMap/home.html\u0026quot;, {\u0026quot;Title\u0026quot;: \u0026quot;Home Page\u0026quot;, \u0026quot;image_form\u0026quot;: ImageForm}\r)\r Upload to S3 bucket Install boto3 package and django-storages. Add to installed packages. Additionally, provide Key:Value AWS credentials to access the bucket and change the default file storage to S3.\npip install django-storages\rpip install boto3\r in settings.py\nINSTALLED_APPS = [\r...\r'storages',\r]\rAWS_ACCESS_KEY_ID = \u0026quot;\u0026quot;\rAWS_SECRET_ACCESS_KEY = \u0026quot;\u0026quot;\rAWS_STORAGE_BUCKET_NAME = \u0026quot;\u0026quot;\rAWS_S3_FILE_OVERWRITE = False\rAWS_DEFAULT_ACL = None\rDEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'\rAWS_QUERYSTRING_AUTH = False // removes the query string\r NOTE: Make the bucket public to be able to make HTTP request\nProvide policy to make our s3 bucket public. By default, the bucket is private and no read/wrtie access is provided for user from outside the s3 page. There are other ways to access private bucket by either Limiting access to specific IP addresses or Restricting access to a specific HTTP referer. For simplicity we make the bucket public.\n{\r\u0026quot;Version\u0026quot;:\u0026quot;2012-10-17\u0026quot;,\r\u0026quot;Statement\u0026quot;:[\r{\r\u0026quot;Sid\u0026quot;:\u0026quot;PublicRead\u0026quot;,\r\u0026quot;Effect\u0026quot;:\u0026quot;Allow\u0026quot;,\r\u0026quot;Principal\u0026quot;: \u0026quot;*\u0026quot;,\r\u0026quot;Action\u0026quot;:[\u0026quot;s3:GetObject\u0026quot;,\u0026quot;s3:GetObjectVersion\u0026quot;],\r\u0026quot;Resource\u0026quot;:[\u0026quot;arn:aws:s3:::DOC-EXAMPLE-BUCKET/*\u0026quot;]\r}\r]\r}\r Accept non-geotagged images At this point, we should be able to upload geotagged images to s3 bucket. Non-geotagged images are not yet accepted by the model and thus we create seperate model for it.\nAdditional resource\nWe now make separate model for accepting non-geotagged images similar to ImageUpload model but without PointField.\nclass Photos(models.Model):\ruser = models.ForeignKey(User, null=True, on_delete=models.CASCADE)\rimage = models.ImageField(upload_to='photos/',null=True,blank=False)\rdate_created = models.DateTimeField(auto_now_add=True, null=True)\rimage_url = models.URLField(max_length=250, null=True, blank=False)\rclass Meta:\rverbose_name = 'Photo'\rverbose_name_plural = 'Photos'\rdef __str__(self):\rreturn self.user.username + \u0026quot; uploaded image \u0026quot;+ self.image.name\r In views.py file, extend the home_page function to add a fallback for non-geotagged images.\nif request.method == \u0026quot;POST\u0026quot;:\r# images will be in request.FILES\rpost_request, files_request = request.POST, request.FILES\rform = PhotoForm(post_request or None, files_request or None)\rfiles = request.FILES.getlist(\r\u0026quot;images\u0026quot;\r) # returns files: [\u0026lt;InMemoryUploadedFile: Image_name.jpg (image/jpeg)\u0026gt;, \u0026lt;InMemoryUploadedFile: Image_name.jpg (image/jpeg)\u0026gt;]\rif form.is_valid():\ruser = request.user\rfor f in files:\r# returns \u0026lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=480x360 at 0x1ED0CCC6280\u0026gt;\rimg = Image.open(f) try:\rgeotags = get_geotagging(img._getexif())\rgeoimage = ImageUpload(user=user, image=f)\rgeoimageimg_upload.image_url = geoimage.image.url\r# X is longitude, Y is latitude, Point(X,Y) ; returns eg SRID=4326;POINT (11.88454 43.46708)\rgeoimage.geom = Point(get_coordinates(geotags))\rgeoimage.save()\rexcept:\rnongeoimage = Photos(user=user, image=f)\rnongeoimage.image_url = nongeoimage.image.url\rnongeoimage.save()\relse:\rprint(\u0026quot;Form invalid\u0026quot;)\rreturn redirect(\u0026quot;home\u0026quot;)\relse:\rImageform = PhotoForm()\rreturn render(\rrequest, \u0026quot;GisMap/home.html\u0026quot;, {\u0026quot;Title\u0026quot;: \u0026quot;Home Page\u0026quot;, \u0026quot;image_form\u0026quot;: ImageForm}\r)\r Accept multiple images Make a new form which accepts multiple image files to be uploaded at once.\nclass PhotoForm(forms.ModelForm):\rimages = forms.FileField(widget=forms.ClearableFileInput(attrs={'multiple': True}))\rclass Meta:\rmodel = Photos\rfields = ('images',)\r In home.html, add multiple attribute to allow for multiple selection of images at once.\n\u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt;\r\u0026lt;label for=\u0026quot;note-image\u0026quot;\u0026gt;\u0026lt;/label\u0026gt;\r\u0026lt;input type=\u0026quot;file\u0026quot; name=\u0026quot;images\u0026quot; class=\u0026quot;form-control-file\u0026quot; id=\u0026quot;note-image\u0026quot; multiple\u0026gt;\r\u0026lt;/div\u0026gt;\r Final Note: At this point, you should be able to upload multiple Images to the AWS S3 bucket and have coordinates extracted the geo-tagged images and segregate non-geotagged images.\nYou learnt-\n How to Setup GeoDjango How to Setup AWS S3 bucket How to Extract meta data from Image and store in database using PointField   These steps will ensure you have multiple images uploaded at once and all the geolocation information can be stored in database, which later can be import to QGIS for data visualisation. Although both postgresql and django admin allows users to visualise the data.\n ","date":1621857354,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621857354,"objectID":"358b17730b7a6c42374df40ddf72985c","permalink":"https://amanbagrecha.github.io/post/django/django-image-upload/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/django/django-image-upload/","section":"post","summary":"we look into how to upload multiple geo-tagged/non-geotagged images to aws s3 using plain Django and postgresql as databbase.","tags":[],"title":"How to Upload Multiple Geotagged Images in Django","type":"post"},{"authors":[],"categories":["Django"],"content":"Overview Ever wanted to send email with attachements that too in django? And have the attachments created from the user input? This post tries to solve exactly that.\nMain steps In this blog we create PDF using Report Lab and email it to the user using gmail SMTP service. All actions are performed in Django.\nStep 1 : create django view to serialize data To begin with, we create a view CreatePDF which accepts POST request and the data gets passed onto CreatePDFSerializer which serializes our data and validates it. If our data is valid, we generate PDF using generate_pdf function and email to the recipent (emailaddress of the users) using the sendPDF function. If everything does not execute properly, we return an error response else a success.\nThe local variable myresponse is a dictionary which helps us manage the response for each return statement in the correct format as expected by response method.\nSUCCESS = 'success'\rERROR = 'error'\rmessage_list = ['response', 'status', 'message'] # eg: [\u0026quot;success\u0026quot;, 201, \u0026quot;successfully upload the file\u0026quot;]\r@csrf_exempt\r@api_view(['POST',])\rdef CreatePDF(request):\rmyresponse = {k: [] for k in message_list}\rtry:\rmyData = request.data\r# serialier the data\rserializer = serializers.CreatePDFSerializer(data=myData) if serializer.is_valid():\rtry:\rsendPDF(**myData.dict()) # create pdf and send email\rexcept Exception as e:\rRequestResponse(\rmyresponse,\rERROR,\rstatus.HTTP_400_BAD_REQUEST,\r{\u0026quot;Email\u0026quot;: [\u0026quot;Could not send mail!\u0026quot;]},\r)\rreturn Response(data=myresponse)\raccount = serializer.save()\rRequestResponse(\rmyresponse,\rSUCCESS,\rstatus.HTTP_201_CREATED,\r{\u0026quot;Success\u0026quot;: [f\u0026quot;Inspection Report e-mailed to {account.EmailAddress}!\u0026quot;]},\r)\rreturn Response(data=myresponse)\rRequestResponse(\rmyresponse, ERROR, status.HTTP_400_BAD_REQUEST, serializer.errors\r)\rreturn Response(data=myresponse)\rexcept Exception as e:\rprint(e)\rRequestResponse(\rmyresponse,\rERROR,\rstatus.HTTP_500_INTERNAL_SERVER_ERROR,\r{\u0026quot;Error\u0026quot;: [\u0026quot;Internal Server Error\u0026quot;]},\r)\rreturn Response(data=myresponse)\r step 2: Generate PDF using Report Lab In views.py we create a function to generate pdf using Report Lab package. This allows us to define the page size and line strings with text placement to be included.\ndef generate_pdf(**Mydata):\ry = 700\rbuffer = io.BytesIO() # in memory create pdf\rp = canvas.Canvas(buffer, pagesize=letter)\rp.setFont('Helvetica', 14)\rp.drawString(220, y, Mydata['Title'])\rp.drawString(450, y, 'Date:' + timezone.now().strftime('%Y-%b-%d'))\rp.line(30, 675, 550, 675)\rp.drawString(220, y - 300, 'Time'\r+ str(Mydata['time']))\rp.showPage()\rp.save()\rpdf = buffer.getvalue()\rbuffer.close()\rreturn pdf\r step 3: Send Email via SMTP backend In views.py, we create sendPDF function which calls the generate_pdfto generate PDF and attaches the pdf to the email using the EmailMessage class method attach. We additionally need to setup backend for smtp service and host user which is to be done in settings.py.\n# views.py\rdef sendPDF(**Mydata):\rpdf = generate_pdf(**Mydata)\rmsg = EmailMessage(Mydata['Title'], \u0026quot; Your Report is ready! \u0026quot;, settings.EMAIL_HOST_USER, to=[Mydata['EmailAddress']])\rmsg.attach(f\u0026quot;{Mydata['Title']}.pdf\u0026quot;, pdf, 'application/pdf')\rmsg.content_subtype = \u0026quot;html\u0026quot;\rresp = msg.send()\rprint(\u0026quot;resp:\u0026quot; , resp)\r In settings.py\n# settings.py\rEMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'\rEMAIL_HOST = \u0026quot;smtp.gmail.com\u0026quot;\rEMAIL_HOST_USER = 'your_email@gmail.com'\rEMAIL_HOST_PASSWORD = 'your_password'\rEMAIL_PORT = 587\rEMAIL_USE_TLS = True\r At this point we have been able to successfully setup and send email with attachment.\n","date":1621814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623509499,"objectID":"289a2685a03073bda90bbd566e602118","permalink":"https://amanbagrecha.github.io/post/django/pdf-and-email-creation/","publishdate":"2021-05-24T00:00:00Z","relpermalink":"/post/django/pdf-and-email-creation/","section":"post","summary":"In this blog we create PDF using `Report Lab` and email it to the user using gmail SMTP service. All actions are performed in Django.","tags":[],"title":"Django rest framework PDF creation and email via gmail SMTP and reportLab","type":"post"},{"authors":[],"categories":["Openlayers"],"content":"Overview In this small demo-blog we look into how to make polygon selections on the map and calculate the area of that polygon on-the-fly. We use openlayers v6 for client side and geoserver to save our vector layers for this exercise.\nI assume readers to have familiarity with setting up geoserver and basics of openlayers.\nStep 1: Setup openlayers Openlayers requires you to add these cdns to add their functionality into our application.\nlink necessary cdns \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://cdn.jsdelivr.net/gh/openlayers/openlayers.github.io@master/en/v6.5.0/css/ol.css\u0026quot; type=\u0026quot;text/css\u0026quot;\u0026gt;\r\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/gh/openlayers/openlayers.github.io@master/en/v6.5.0/build/ol.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r We are using openlayers to render the request response. since the output of the WFS request is json, we create a new layer with vector source and format as geojson. The strategy:ol.loadingstrategy.bbox tells openlayers to only load features within the bbox. Simply put, if we move to different location, only features within that bbox will appear.\n// setup geoserver port\rvar geoserver_ip = 'http://120.0.0.1'\rvar geoserver_port = '8080'\r// define vector source\rvar myFlSource = new ol.source.Vector({\rformat: new ol.format.GeoJSON(),\rurl: function (extent){\rreturn ( geoserver_ip +':' + geoserver_port + '/geoserver/dronnav/ows?service=WFS\u0026amp;version=1.1.0\u0026amp;request=GetFeature\u0026amp;typeName=dronnav%3Aflorida_bp\u0026amp;maxFeatures=10000\u0026amp;outputFormat=application/json\u0026amp;srsname=EPSG:4326\u0026amp;' + 'bbox=' + extent.join(',') + ',EPSG:4326' );\r},\rstrategy:ol.loadingstrategy.bbox,\r});\r We perform WFS request from geoserver to get our layer florida_bp in this case. The parameters are as explained as follows\n  service=WFS : web feature service to perform interaction\n  typename=workspace:florida_bp : specify the workspace and layer name\n  version=1.1.0 : version number\n  maxFeatures = 10000 : since WFS request is computationaly expensive, we restrict to only load 10000 features.\n  request=GetFeature : request type. There are several other which can be found here\n  outputFormat=application/json : the output format as response\n  srsname=EPSG:4326 : coordinate reference system to display on the map\n  bbox= : bounding box\n  // define vector layer\rvar floridaLayer = new ol.layer.Vector({\rsource: myFlSource,\rstyle: new ol.style.Style({\rfill: new ol.style.Fill({\rcolor: 'rgba(1, 1, 255, .2)',\r}),\rstroke: new ol.style.Stroke({\rcolor: 'rgba(1, 1, 255, .5)',\rwidth: 2,\r}),\r}),\rminZoom: 16, // this will allows us to send request only when the zoom is atleast 16\r});\r Once the layer is defined, we need to add this layer to the map. We can either use map.addLayer(layername) or add to array in the map (Fig.1)\n// add ESRI basemap\rvar project_maplayer = new ol.layer.Tile({\rsource: new ol.source.XYZ({\rattributions: ['Powered by Esri',\r'Source: Esri, DigitalGlobe, GeoEye, Earthstar Geographics, CNES/Airbus DS, USDA, USGS, AeroGRID, IGN, and the GIS User Community'],\rattributionsCollapsible: false,\rurl: 'https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\rmaxZoom: 23\r}),\rzIndex: 0\r});\r// add view with projection set to EPSG 4326 for the map\rvar project_view = new ol.View({\rprojection: 'EPSG:4326',\rcenter: [-81.80808208706726, 27.285095000261222],\rzoom: 7,\r});\r// define the map with all the layers created previously\rvar Projectmap = new ol.Map({\rlayers: [project_maplayer, floridaLayer],\roverlays: [overlay],\rtarget: 'project_map', // the div element `id` in html page\rview: project_view,\r});\r \rFig.1 -The Map layer with building footprints (floridaLayer) added to the map with the style we specified for each feature\r\rGet feature info on click After adding basemap and our layer to the map served via geoserver, we are now ready to get information on-click. We use forEachFeatureAtPixel method on our layer to send a WFS request to our geoserver and recive a response in json format. We change the style of the building on click (Fig.2). The area is calculated using formatArea function which utilises ol.sphere.getArea and transform method to calculate area and change CRS.\n/* select ploygon the feature and get area and store the features */\rvar selected = []; // contains all features\rvar selected_area = []; // contains area of feature, one-to-one\rProjectmap.on('singleclick', function (e) {\rProjectmap.forEachFeatureAtPixel(e.pixel, function (f, l) {\rvar mycoordinate = e.coordinate\rstoref = f // feature\r/* if click is on polygon, then select the feature */\rif ( f.getGeometry() instanceof ol.geom.MultiPolygon ) {\rvar selIndex = selected.indexOf(f);\r// console.log(selIndex)\rif (selIndex \u0026lt; 0) {\rselected.push(f);\rselected_area.push( formatArea(f) ); // formatArea function returns the area in ft2\rf.setStyle(highlightStyle); // change style on click\r} else {\rselected.splice(selIndex, 1);\rselected_area.splice( selIndex, 1);\rf.setStyle(undefined);\r}\r}\r})\r/* update the tags with no of selected feature and total area combined */\rdocument.getElementById('status-selected').innerHTML = '\u0026amp;nbsp;' + selected.length + ' selected features';\rdocument.getElementById('status-selected_area').innerHTML = '\u0026amp;nbsp;' + selected_area.reduce(getSum, 0) + ' ft\u0026lt;sup\u0026gt;2\u0026lt;/sup\u0026gt;';\r});\r/* style for selected feature on click */\rvar highlightStyle = new ol.style.Style({\rfill: new ol.style.Fill({\rcolor: '#f0b88b',\r}),\rstroke: new ol.style.Stroke({\rcolor: '#f0b88b',\rwidth: 3,\r}),\r});\r/* function for calculating area of the polygon (feature) selected */\rfunction formatArea (polygon){\rvar area = ol.sphere.getArea(polygon.getGeometry().transform('EPSG:4326', 'EPSG:3857')); // transform to projected coordinate system.\rvar output;\routput = Math.round(area * 100*10.7639) / 100 ; //in ft2\rpolygon.getGeometry().transform('EPSG:3857', 'EPSG:4326' ) //convert back to geographic crc\rreturn output;\r}\r/* function for array sum */\rfunction getSum(total, num) {\rreturn total + Math.round(num);\r}\r \rFig.2 -The floridaLayer building footprints selected with the style we specified for each feature\r\rFinal comments This post demonstrates the use of strategy:ol.loadingstrategy.bbox to load only the features that cover the bounding box. We use this strategy since WFS service is resouce intensive and our server cannot handle millions of HTTP request at once.\nWe also see the use of forEachFeatureAtPixel method to select our building footprints. On click of the feature we change the style using setStyle method.\nAdditionally, we saw how to change projection on-the-fly using ol.sphere.getArea method. A word of caution while using EPSG:3857. My AOI was on the equator and thus calculating area does not result in significant error. But if the AOI is in temperate zone then adopt suitable projection CRS.\nLayer Credit: Microsoft buidling footprints https://github.com/microsoft/USBuildingFootprints\n","date":1621814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621867485,"objectID":"5b67cf10fb9f49f2ef304c7a0f7c09f4","permalink":"https://amanbagrecha.github.io/post/openlayers/polygon-selection-and-area-calculation-in-openlayers/","publishdate":"2021-05-24T00:00:00Z","relpermalink":"/post/openlayers/polygon-selection-and-area-calculation-in-openlayers/","section":"post","summary":"Select multiple polygons (parcels) and calculate area on the fly in openlayers","tags":[],"title":"Polygon Selection and  Area Calculation in Openlayers","type":"post"},{"authors":[],"categories":["Django"],"content":"\rWhat will you learn Too Long; Didn\u0026rsquo;t Read \n   Markdown Less     DRF Create API end points for CRUD   Token Authentication Add security and authorised access   Fetch API calls Consume API from front-end   Password Reset Send email to reset your forgotton password     1. Step one : Basic Django Project setup Create virtual environment\nconda create --name djangoEnv\r Activate the environment\nconda activate djangoEnv\r Install the dependencies\nconda install django\r Now, in your command line\ncreate project django-admin startproject tutorial\ncreate app python manage.py startapp Accountsapp\ncreate superuser python manage.py createsuperuser\nNow that we have the project and app installed your structure should look like this (insert picture here)\nRegister the app in file as follows\nIn settings.py\nInstalled_apps = [ 'Accountsapp.apps.AccountsappConfig',\r...\r]\r We now create our own custom model named MyAccounts\nIn models.py\nfrom django.db import models\rfrom django.contrib.auth.models import AbstractBaseUser, BaseUserManager\rfrom django.conf import settings\rfrom django.db.models.signals import post_save\rfrom django.dispatch import receiver\rfrom rest_framework.authtoken.models import Token\rclass MyAccountManager(BaseUserManager):\rdef create_user(self, email, username, password=None):\rif not email:\rraise ValueError('Users must have an email address')\rif not username:\rraise ValueError('Users must have a username')\ruser = self.model(\remail=self.normalize_email(email),\rusername=username,\r)\ruser.set_password(password)\ruser.save(using=self._db)\rreturn user\rdef create_superuser(self, email, username, password):\ruser = self.create_user(\remail=self.normalize_email(email),\rpassword=password,\rusername=username,\r)\ruser.is_admin = True\ruser.is_staff = True\ruser.is_superuser = True\ruser.save(using=self._db)\rreturn user\r# creating custom model of \u0026quot;User\u0026quot; base model. class MyAccount(AbstractBaseUser):\remail = models.EmailField(verbose_name=\u0026quot;email\u0026quot;, max_length=60, unique=True)\rusername = models.CharField(max_length=30, unique=True)\rdate_joined\t= models.DateTimeField(verbose_name='date joined', auto_now_add=True)\rlast_login\t= models.DateTimeField(verbose_name='last login', auto_now=True)\ris_admin\t= models.BooleanField(default=False)\ris_active\t= models.BooleanField(default=True)\ris_staff\t= models.BooleanField(default=False)\ris_superuser\t= models.BooleanField(default=False)\rUSERNAME_FIELD = 'email' # username_field is the one which should be unique and will be compared by django for not creating multiple users with same email.\rREQUIRED_FIELDS = ['username'] objects = MyAccountManager()\rdef __str__(self):\rreturn self.email\r# For checking permissions. to keep it simple all admin have ALL permissons\rdef has_perm(self, perm, obj=None):\rreturn self.is_admin\r# Does this user have permission to view this app? (ALWAYS YES FOR SIMPLICITY)\rdef has_module_perms(self, app_label):\rreturn True\r To tell django we are overwriting the default user model, we do the following\nIn settings.py\nAUTH_USER_MODEL = Accounts.MyAccounts\r Now we makemigrates to register the model in our database\npython manage.py makemigrations\rpython manage.py migrate\r And for the model to be visible in admin section we do the following\nIn admin.py\nfrom django.contrib import admin\rfrom .models import MyAccount\radmin.site.register(MyAccount) # Register your models here.\r For now the our project is setup. We move to Django Rest Framework setup\n2. Setup Django Rest Framework with Authentication Install dependeny\nconda install djangorestframework\r Like any other app, django rest framework is also an app. so we add it to the list of installed apps. We additionally add authtoken app for user authentication which we are shortly going to intergrate in our CRUD application\nIn settings.py\nINSTALLED_APPS = [\r# my apps\r'Accountsapp.apps.AccountsappConfig',\r# restframework\r'rest_framework',\r'rest_framework.authtoken',\r...\r]\r We are going to be using Token Authentication in this application. DRF documentation recommends it as the default. Let Us setup the Default authentication class before actually utilising it.\nIn settings.py\nREST_FRAMEWORK¬†=¬†{\r'DEFAULT_AUTHENTICATION_CLASSES':¬†[\r'rest_framework.authentication.TokenAuthentication',\r]\r}\r The last thing before we actually start writing code is to perform migration. The¬†rest_framework.authtoken¬†app provides Django database migrations.\nAs done previously on command line\npython manage.py makemigrations\rpython manage.py migrate\r We have completed the logistics for setting up DRF\n3. Building CRUD application We would first create a folder called api inside our to seperate codebase for API and vanila CRUD\nInside API folder create four files,\n __init__.py serializers.py views.py urls.py  In serializers.py\nfrom rest_framework import serializers from Accountsapp.models import MyAccount # import our custom model\r# provide fields in meta, expression and in MyAccount. for admin page login and edit, is_admin and is_staff should be true\rclass RegistrationSerializer(serializers.ModelSerializer):\r# additional fields password2 = serializers.CharField(style={'input_type': 'password'}, write_only=True)\ris_superuser =serializers.BooleanField(write_only=True)\rclass Meta:\rmodel = MyAccount\r# mention the fields you want to display when request is sent. fields = ['id','email', 'username', 'password', 'password2', 'is_superuser']\rextra_kwargs = {\r'password': {'write_only': True}, # tells django to not display the password for others to see\r}\tdef\tsave(self):\raccount = MyAccount(\remail=self.validated_data['email'],\rusername=self.validated_data['username'],\r# is_admin=self.validated_data['is_admin'],\ris_superuser= self.validated_data['is_superuser'],\r)\rpassword = self.validated_data['password']\rpassword2 = self.validated_data['password2']\rif password != password2:\rraise serializers.ValidationError({'password': 'Passwords must match.'})\raccount.set_password(password)\raccount.save()\rreturn account\rclass UpdateSerializer(serializers.ModelSerializer):\rclass Meta:\rmodel = MyAccount\r# mention the fields you want to display when request is sent. fields = ['id', 'username', 'email']\rextra_kwargs = {\r'password': {'read_only': True}, # password cannot be edited from here\r}\r Note : Do not try to update the password from serializers. There is another technique which we will deal with in later section.\n The serializers in REST framework work very similarly to Django‚Äôs Form and ModelForm classes. The two major serializers that are most popularly used are ModelSerializer and HyperLinkedModelSerialzer.\n In views.py\nfrom rest_framework import status\rfrom rest_framework.response import Response\rfrom rest_framework.permissions import IsAuthenticated, IsAdminUser\rfrom django.contrib.auth import authenticate\rfrom rest_framework.authentication import TokenAuthentication\rfrom rest_framework.decorators import api_view, authentication_classes, permission_classes\rfrom . import serializers from Accountsapp.models import MyAccount\rfrom rest_framework.authtoken.models import Token\r# user views\rfrom django.http import JsonResponse\rfrom django.views.decorators.csrf import csrf_exempt\rfrom rest_framework.parsers import JSONParser\rfrom django.core.exceptions import ObjectDoesNotExist\rimport json\r# login {built-in django}\rfrom django.contrib.auth import login from django.contrib.auth.decorators import login_required\r# get all users\r@api_view([\u0026quot;GET\u0026quot;])\r@csrf_exempt\r@permission_classes([IsAuthenticated,])\r@authentication_classes([TokenAuthentication])\rdef get_users(request):\rtry:\ruser_profile = MyAccount.objects.all() serializer = serializers.RegistrationSerializer(user_profile, many=True)\rreturn Response( {'USER_PROFILE':serializer.data}, status= status.HTTP_200_OK)\rexcept ObjectDoesNotExist:\rreturn JsonResponse({'Response': 'You do not have authorization to access this page'}, status=status.HTTP_401_UNAUTHORIZED)\r# get given user\r@api_view(['GET'])\r@csrf_exempt\r@permission_classes([IsAuthenticated,])\r@authentication_classes([TokenAuthentication])\rdef get_given_user(request, pk):\rtry:\ruser_profile = MyAccount.objects.get(pk=pk)\rexcept ObjectDoesNotExist:\rreturn JsonResponse({\u0026quot;missing\u0026quot;: \u0026quot;The requested object does not exist\u0026quot;}, status=status.HTTP_404_NOT_FOUND)\rif request.method == 'GET': serializer = serializers.RegistrationSerializer(user_profile)\rtoken = Token.objects.get(user=user_profile).key\rreturn JsonResponse({'given_user_profile': serializer.data, 'token':token})\r# add user\r@csrf_exempt\r@api_view(['POST'])\rdef user_add_view(request):\rserializer = serializers.RegistrationSerializer( data=request.data)\rif serializer.is_valid():\raccount = serializer.save()\rtoken, _ = Token.objects.get_or_create(user=account)\rreturn Response(serializer.data, status=status.HTTP_201_CREATED, headers={'Authorization': 'Token ' + token.key})\rreturn Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\r# update user\r@api_view([\u0026quot;PUT\u0026quot;,'GET'])\r@csrf_exempt\r@permission_classes([IsAuthenticated,])\r@authentication_classes([TokenAuthentication])\rdef update_user(request, pk):\rtry:\ruser_profile = MyAccount.objects.get(id=pk)\rexcept ObjectDoesNotExist:\rreturn Response({'response': \u0026quot;given object does not exist\u0026quot;}, status=status.HTTP_404_NOT_FOUND)\ruser = request.user\rtry:\rdata = {i:j for i,j in request.query_params.items()}\rprint(data)\rserializer = serializers.UpdateSerializer(user_profile, data=data)\rif serializer.is_valid():\ruser= serializer.save()\rtoken, _ = Token.objects.get_or_create(user=user)\rreturn Response({\u0026quot;response\u0026quot;: \u0026quot;success\u0026quot;, 'data' :serializer.data}, status=status.HTTP_201_CREATED, headers={'Authorization': 'Token ' + token.key})\rreturn Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\rexcept ObjectDoesNotExist as e:\rreturn JsonResponse({'error': str(e)}, safe=False, status=status.HTTP_404_NOT_FOUND)\rexcept Exception:\rreturn JsonResponse({'error': 'Something terrible went wrong'}, safe=False, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\r# delete user\r@api_view([\u0026quot;DELETE\u0026quot;,'GET']) @csrf_exempt\r@permission_classes([IsAuthenticated])\r@authentication_classes([TokenAuthentication])\rdef delete_user(request, pk):\rtry:\ruser_profile = MyAccount.objects.get(id=pk)\rexcept ObjectDoesNotExist:\rreturn JsonResponse({'response': \u0026quot;given object does not exist\u0026quot;}, safe=False, status=status.HTTP_404_NOT_FOUND)\ruser = request.user\rif user_profile != user: return JsonResponse({'response':\u0026quot;You don't have permission to delete the record.\u0026quot;}, safe=False, status=status.HTTP_401_UNAUTHORIZED)\rtry:\ruser_profile.delete() #retuns 1 or 0\rreturn JsonResponse({'user_delete': \u0026quot;record deleted\u0026quot;}, safe=False, status=status.HTTP_200_OK)\rexcept ObjectDoesNotExist as e:\rreturn JsonResponse({'error': str(e)}, safe=False, status=status.HTTP_404_NOT_FOUND)\rexcept Exception:\rreturn JsonResponse({'error': 'Something terrible went wrong'}, safe=False, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\r# login view and get token\r@api_view([\u0026quot;POST\u0026quot;, ])\rdef drflogin(request):\remail = request.data.get(\u0026quot;email\u0026quot;)\rusername = request.data.get(\u0026quot;username\u0026quot;)\rpassword = request.data.get(\u0026quot;password\u0026quot;)\raccount = MyAccount.objects.filter(email=email) | MyAccount.objects.filter(username=username)\rif not account:\rreturn Response({\u0026quot;error\u0026quot;: \u0026quot;Login failed\u0026quot;}, status=status.HTTP_401_UNAUTHORIZED)\r# authenticate(email=email, password=password) # returns none if not authenticated\raccount = authenticate(email=account[0].email, password=password)\rtoken, _ = Token.objects.get_or_create(user=account)\rlogin(request,account) renderer= Response({\u0026quot;response\u0026quot; : \u0026quot;Successfully authenticated\u0026quot;, \u0026quot;pk\u0026quot;: account.pk, \u0026quot;username\u0026quot;: account.username, \u0026quot;token\u0026quot;: token.key }, template_name= \u0026quot;Accountsapp/loginuser.html\u0026quot;, headers={'Authorization': 'Token ' + token.key})\rreturn renderer\r Setup end points for our API\nIn views.py\nfrom django.urls import path, include\rfrom . import views as drf_views\rapp_name = 'Accountsapp'\rurlpatterns = [\rpath('drf_users/', drf_views.get_users, name= 'drf_users'),\rpath('drf_user/\u0026lt;int:pk\u0026gt;/', drf_views.get_given_user, name= 'drf_get_user'),\rpath('drf_updateuser/\u0026lt;int:pk\u0026gt;/', drf_views.update_user, name= 'drf_updateusers'),\rpath('drf_deleteuser/\u0026lt;int:pk\u0026gt;/', drf_views.delete_user, name= 'drf_deleteuser'),\rpath('drf_adduser/', drf_views.user_add_view, name= 'drf_adduser'),\rpath('drf_login/', drf_views.drflogin, name='drf_login'),\r]\r We first create users and then test delete, update and show users functionality of our API. We will use Postman for timebeing. Later we will built the front-end to perform all these actions.\nPOST  REQUEST: ADD USER http://127.0.0.1:8000/drf_adduser/\r GET  REQUEST: GET USERS API end point\nhttp://127.0.0.1:8000/drf_users/\r Using curl and passing authorization token\ncurl --location --request GET 'http://127.0.0.1:8000/drf_users/' \\\r--header 'Authorization: Token 92cc8c32edb7bd111b89552a3031f918d2df5613'\r Using postman\nDEL  REQUEST: DELETE USER API end point\nhttp://127.0.0.1:8000/drf_deleteuser/\u0026lt;int:pk\u0026gt;\r Using curl and passing authorization token\ncurl --location --request DELETE 'http://127.0.0.1:8000/drf_deleteuser/21' \\\r--header 'Authorization: Token 1529e77c59999f819649828a5e9174ba44bd6bb4'\r Using postman\nPUT  REQUEST: UPDATE USER API end point\nhttp://127.0.0.1:8000/drf_updateuser/1/?username=updated_username_here\u0026amp;email=updated_email_here\r Using curl and passing authorization token\ncurl --location --request PUT 'http://127.0.0.1:8000/drf_updateuser/8/?username=rcbfl\u0026amp;email=rcbfl@gmail.com' \\\r--header 'Authorization: Token 506ce0bbf7fa50f613678024586669d9b6bd82a0'\r using postman GET  REQUEST: GET USER API end point\nhttp://127.0.0.1:8000/drf_user/\u0026lt;int:pk\u0026gt;\r Using curl and passing authorization token\ncurl --location --request GET 'http://127.0.0.1:8000/drf_user/8' \\\r--header 'Authorization: Token 506ce0bbf7fa50f613678024586669d9b6bd82a0'\r using postman\nFront end setup In root directory create folder templates\\Accountsapp\\ and create RegiserUser.html file in it. Create form field in the file as follows\n\u0026lt;form class=\u0026quot;form-horizontal\u0026quot; action=\u0026quot;\u0026quot; method=\u0026quot;post\u0026quot; id=\u0026quot;myForm\u0026quot; autocomplete=\u0026quot;off\u0026quot;\u0026gt;\r{% csrf_token %}\r\u0026lt;!-- Name input--\u0026gt;\r\u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt;\r\u0026lt;label class=\u0026quot;col-md-3 control-label\u0026quot; for=\u0026quot;username\u0026quot;\u0026gt;Name\u0026lt;/label\u0026gt;\r\u0026lt;div class=\u0026quot;col-md-9\u0026quot;\u0026gt;\r\u0026lt;input id=\u0026quot;username\u0026quot; name=\u0026quot;username\u0026quot; type=\u0026quot;text\u0026quot; placeholder=\u0026quot;Your username\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;!-- Email input--\u0026gt;\r\u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt;\r\u0026lt;label class=\u0026quot;col-md-3 control-label\u0026quot; for=\u0026quot;email\u0026quot;\u0026gt;Your E-mail\u0026lt;/label\u0026gt;\r\u0026lt;div class=\u0026quot;col-md-9\u0026quot;\u0026gt;\r\u0026lt;input id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; type=\u0026quot;email\u0026quot; placeholder=\u0026quot;Your email\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;!-- password body --\u0026gt;\r\u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt;\r\u0026lt;label class=\u0026quot;col-md-3 control-label\u0026quot; for=\u0026quot;password\u0026quot;\u0026gt;Password\u0026lt;/label\u0026gt;\r\u0026lt;div class=\u0026quot;col-md-9\u0026quot;\u0026gt;\r\u0026lt;input id=\u0026quot;password\u0026quot; name=\u0026quot;password\u0026quot; type=\u0026quot;password\u0026quot; placeholder=\u0026quot;Your password\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;!-- password body --\u0026gt;\r\u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt;\r\u0026lt;label class=\u0026quot;col-md-3 control-label\u0026quot; for=\u0026quot;password2\u0026quot;\u0026gt;Password2\u0026lt;/label\u0026gt;\r\u0026lt;div class=\u0026quot;col-md-9\u0026quot;\u0026gt;\r\u0026lt;input id=\u0026quot;password2\u0026quot; name=\u0026quot;password2\u0026quot; type=\u0026quot;password\u0026quot; placeholder=\u0026quot;confirm password\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;!-- superuser input --\u0026gt;\r\u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt;\r\u0026lt;label class=\u0026quot;col-md-3 control-label\u0026quot; for=\u0026quot;superuser\u0026quot;\u0026gt;Is superuser\u0026lt;/label\u0026gt;\r\u0026lt;div class=\u0026quot;col-md-3\u0026quot;\u0026gt;\r\u0026lt;input id=\u0026quot;issuperuser\u0026quot; name=\u0026quot;issuperuser\u0026quot; type=\u0026quot;checkbox\u0026quot; class=\u0026quot;form-control\u0026quot; \u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;!-- Form actions --\u0026gt;\r\u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt;\r\u0026lt;div class=\u0026quot;col-md-6 text-left\u0026quot;\u0026gt;\r\u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary btn-lg\u0026quot;\u0026gt;Submit\u0026lt;/button\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;/fieldset\u0026gt;\r\u0026lt;/form\u0026gt;\r Once the form is created, we now need to take the input from the form and send to the register user API drf_adduser/.\nIn RegisterUser.html\n\u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt;\rfunction getCookie(name) {\rvar cookieValue = null;\rif (document.cookie \u0026amp;\u0026amp; document.cookie !== '') {\rvar cookies = document.cookie.split(';');\rfor (var i = 0; i \u0026lt; cookies.length; i++) {\rvar cookie = cookies[i].trim();\r// Does this cookie string begin with the name we want?\rif (cookie.substring(0, name.length + 1) === (name + '=')) {\rcookieValue = decodeURIComponent(cookie.substring(name.length + 1));\rbreak;\r}\r}\r}\rreturn cookieValue;\r}\rvar csrftoken = getCookie('csrftoken');\rfunction fetchcall(event) {\revent.preventDefault();\rconsole.log('form submitted');\rvar username = document.getElementById(\u0026quot;username\u0026quot;).value;\rvar email = document.getElementById(\u0026quot;email\u0026quot;).value;\rvar password = document.getElementById(\u0026quot;password\u0026quot;).value;\rvar password2 = document.getElementById(\u0026quot;password2\u0026quot;).value;\rvar issuperuser = document.getElementById(('issuperuser')).checked;\rconsole.log(issuperuser)\rvar url = '/drf_adduser/';\rfetch(url, {\rmethod:'POST',\rheaders:{\r'Content-type':'application/json',\r'X-CSRFToken':csrftoken,\r},\rbody:JSON.stringify({\r'email':email,\r'username':username,\r\u0026quot;password\u0026quot;:password,\r\u0026quot;password2\u0026quot;:password2,\r\u0026quot;is_superuser\u0026quot;: issuperuser\r})\r}\r).then(function(response){\rstore_response= response;\rreturn response.json();\r}).then(function(data){\rstore_data =JSON.stringify(data);\rdocument.getElementById(\u0026quot;message\u0026quot;).innerHTML= store_data;\r}).catch(function(error){\rconsole.error(error);\r});\r}\rvar myForm = document.getElementById(\u0026quot;myForm\u0026quot;);\rconsole.log(username, password, myForm);\rmyForm.addEventListener('submit', fetchcall);\r\u0026lt;/script\u0026gt;\r To make this work in front-end, we need to register the file to Accountsapp/views.py\ndef register_user(request):\r# if request.user.is_authenticated:\rreturn render(request, \u0026quot;Accountsapp/RegisterUser.html\u0026quot;, {'Title': \u0026quot;Register new user\u0026quot;})\r ","date":1621676638,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621676638,"objectID":"acb3f40a2c4ddf66f721a5ff94fad7f7","permalink":"https://amanbagrecha.github.io/post/django/crud-in-django-rest-framework/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/django/crud-in-django-rest-framework/","section":"post","summary":"How to perform Create, Read, Update and Delete operations in Django Rest Framework","tags":["Django"],"title":"Full Fledged CRUD application using DRF and Token Authentication","type":"post"},{"authors":[],"categories":null,"content":"Slides:\n  Part1: Analysis of flood prone region with SAR Imagery\n  Part 2: Future is SAR\n  ","date":1588338000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588338000,"objectID":"ca2131a0abf5237844e3b2eb7d178fbf","permalink":"https://amanbagrecha.github.io/talk/analysis-of-flood-prone-region-with-sar-imagery-using-gee/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/analysis-of-flood-prone-region-with-sar-imagery-using-gee/","section":"event","summary":"Technical presentation on Analysis of Flood Prone Region with SAR Imagery, a case study for Assam.","tags":[],"title":"Analysis of Flood Prone Region with SAR Imagery using GEE","type":"event"},{"authors":null,"categories":null,"content":"Project Setup  A project to demostrate rest-api crud operation in node-express application. Node and express allows for easy api building and super easy to create application.\n create package.json\nnpm init -y\r install express\nnpm install --save express\r in index.js file\nimport express from 'express'; // both are same (works with node 14.5 and above..)\rconst express = require('express'); // old version\r To enable the first line of code for above we have to make changes in package.json as follows\n\u0026quot;type\u0026quot; : \u0026quot;module\u0026quot;,\r run server\nnpm start\r install nodemon package to refresh the server on each save\nnpm install --save-dev nodemon\r In package.json add under scripts. This is done to start application using nodemon.\n\u0026quot;start\u0026quot;: \u0026quot;nodemon index.js\u0026quot;;\r For modularity we create another folder where we would store all our routes create a folder routes/users.js which has the following basic template.\nimport express from 'express';\r// Use the express.Router class to create modular, mountable route handlers\rconst router = express.Router();\r// routes here\r// eg: router.get(...)\r// export the app `router` so that it can be imported in index.js\rexport default router;\r Now import the exported router app to index.js as follows\nimport router from './routes/users.js';\rapp.use(\u0026quot;/people\u0026quot;, router);\r now\nrouter.post('/', (req, res) =\u0026gt; {\r// when making post request, we have access to req.body\ruser_list.push(req.body); // user_list is list of dictoriay contianing all users\r})\r  Next step: Setting up mongo db database npm install mongoose\nimport mongoose from 'mongoose';\r const CONNECTION_URL = \u0026quot;mongodb+srv://\u0026lt;username\u0026gt;:\u0026lt;password\u0026gt;@cluster0.frghl.mongodb.net/\u0026lt;data_basename\u0026gt;?retryWrites=true\u0026amp;w=majority\u0026quot;;\rmongoose.connect(CONNECTION_URL, { useNewUrlParser: true, useUnifiedTopology: true })\r.then(() =\u0026gt; app.listen(PORT, () =\u0026gt; console.log(`Server Running on Port: http://localhost:${PORT}`))) // what to do when we connection is made\r.catch((error) =\u0026gt; console.log(`${error} did not connect`)); // what if it goes wrong\rmongoose.set('useFindAndModify', false);\r We now create schema for our database. Since this is basic crud, we want username, email. we do so by creating user_model.js file inside models folder in root directory.\nimport mongoose from 'mongoose';\rconst postSchema = mongoose.Schema({\rfirstname: String,\rlastname: String,\remail: { // required field\rtype: String,\rrequired: true\r},\rcreatedAt: { type: Date,\rdefault: new Date(),\r},\r})\rvar user_model = mongoose.model('user_model', postSchema);\rexport default user_model;\r After exporting the model, we now import in our functions.js file.\nError messages\nimport { Mongoose } from 'mongoose';\r^^^^^^^^\rSyntaxError: Named export 'Mongoose' not found. The requested module 'mongoose' is a CommonJS module, which may not support all module.exports as named exports.\rCommonJS modules can always be imported via the default export, for example using:\rimport pkg from 'mongoose';\rconst { Mongoose } = pkg;\r ","date":1587945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587945600,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://amanbagrecha.github.io/project/internal-project/","publishdate":"2020-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"A how-to guide to build node express CRUD API.","tags":["other","Node Express","CRUD"],"title":"CRUD Application using node express api","type":"project"},{"authors":["Yashas Venkatesh","Aman Bagrecha","Dhanush S"],"categories":null,"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://amanbagrecha.github.io/publication/conference-paper/","publishdate":"2020-03-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Feasibility Study of Floating Solar Panels over Lakes in Bengaluru City presented at Second ASCE India Conference on ‚ÄúChallenges of Resilient and Sustainable Infrastructure Development in Emerging Economies","tags":["ASCE","FSPV","SOLAR"],"title":"Feasibility Study of Floating Solar Panels over Lakes in Bengaluru City","type":"publication"},{"authors":null,"categories":null,"content":"","date":1582761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://amanbagrecha.github.io/project/external-project/","publishdate":"2020-02-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"Create API end points for DRF-CRUD and add security layer using Token Authentication.","tags":["python","DRF","Django","CRUD"],"title":"Django-rest-framework CRUD Token Authetication Application","type":"project"},{"authors":[],"categories":[],"content":"Introduction to Natural Language Processing By Aman Bagrecha\n What is Natural Language?  Those Languages which are not artificial or computer generated :) Natural Language is what Humans communicate through Eg. English, Hindi, Kannada, French‚Ä¶   What is Natural Language Processing?  Enabling computers to understand Natural Language. Data is the new oil! It has information hidden underneath. Only problem is it is not that simply to extract information.   Why is it complex?  Ambiguity in meaning of sentence  \u0026ndash; ‚ÄúI fought with my brother‚Äù Did he fight along with his brother or against him?\n New words are added everyday Position of adverb/verb can change meaning or mean nothing  \u0026ndash; ‚ÄúHe‚Äôs working hard‚Äù vs ‚ÄúHe‚Äôs hard working‚Äù vs ‚Äúhard he‚Äôs working‚Äù\n Same word can have different meaning based on context  \u0026ndash; Aditya is a friend I can always bank on for help\n\u0026ndash; Aditya is going to the bank\n Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"4eed87b20d2317047790c869717090ef","permalink":"https://amanbagrecha.github.io/slides/nlp-basics/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/nlp-basics/","section":"slides","summary":"Introduction to Natural Language Processing.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"ccc1c1fb30f0ee67f5847513f774972c","permalink":"https://amanbagrecha.github.io/project/store-info-leaflet/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/store-info-leaflet/","section":"project","summary":"store-info is developed to let users access the whereabouts of store. Leaflet, an open-source lightweight JavaScript library has been used for mapping.","tags":["webgis","leaflet"],"title":"Web application to access store information on click of marker!","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://amanbagrecha.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]