<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning | Aman Bagrecha</title>
    <link>https://amanbagrecha.github.io/category/machine-learning/</link>
      <atom:link href="https://amanbagrecha.github.io/category/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>machine learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 09 Jun 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://amanbagrecha.github.io/media/icon_hu34b7b96a7941bf879d4219a76e82104f_4254_512x512_fill_lanczos_center_2.png</url>
      <title>machine learning</title>
      <link>https://amanbagrecha.github.io/category/machine-learning/</link>
    </image>
    
    <item>
      <title>Validating LULC classes in QGIS</title>
      <link>https://amanbagrecha.github.io/post/qgis/validating-lulc-classes-in-qgis/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://amanbagrecha.github.io/post/qgis/validating-lulc-classes-in-qgis/</guid>
      <description>&lt;h2 id=&#34;the-problem-statement&#34;&gt;&lt;strong&gt;The problem statement&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Any land-use land cover classification needs to be validated with ground-truth data to measure the accuracy. A key single-valued statistic to determine the effectiveness of classification is Cohenâ€™s kappa. This validation metric has been fairly widely used for unbalanced classification as well which expresses a level of agreement between two annotators on a classification problem.&lt;/p&gt;
&lt;p&gt;The objective of this quality assessment was to validate the land cover map performed on June, 2020 sentinel-2 imagery by k-means classification algorithm, thus providing a statistical measure of overall class predictions. The validation was done using an independent set of sample points (~500) generated randomly following stratified random sampling design, to capture the variance within the class&lt;/p&gt;
&lt;p&gt;After running the tool, the sample points were manually assigned to the ground-truth class. The ground-truth dataset was taken to be Bing-satellite imagery as a proxy for field data. Each sample point was labelled by visual inspection on the ground-truth dataset.&lt;/p&gt;
&lt;h2 id=&#34;step-1-classify-image&#34;&gt;&lt;strong&gt;Step 1: Classify Image&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Load raster Image&lt;/li&gt;
&lt;li&gt;Open &lt;code&gt;K-means clustering for grids&lt;/code&gt; under SAGA tools. Select the raster Image as &lt;code&gt;grid&lt;/code&gt; and in this case we specify 4 classes&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/xdx5Tsn.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.1 -K-means clustering on sentinel-2 Image&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Click &lt;code&gt;Run&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;At this stage we have unsupervised k-means clustering output ready &lt;code&gt;(Fig.2)&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/eW0cOXE.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.2 -classification of RR Nagar, Bengaluru. Classes- Forest, Urban, water, Bareland&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-2-convert-to-polygon-vector-format&#34;&gt;&lt;strong&gt;Step 2: Convert to polygon (vector format)&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Select &lt;code&gt;Polygonize (Raster to Vector)&lt;/code&gt; tool under &lt;code&gt;GDAL&lt;/code&gt;-&amp;gt;&lt;code&gt;Raster Conversion&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select the classified image as input. Leave everything else as default. The output would be a &lt;code&gt;Vectorised&lt;/code&gt; scratch layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/36nk2tF.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.3 -Convert Raster to vector&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Note the name of the field (&lt;code&gt;DN&lt;/code&gt; here). This will be used later.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Fix geometries (this step is important here to avoid any error in further steps) &lt;code&gt;Vector Geometry&lt;/code&gt;-&amp;gt;&lt;code&gt;Fix Geometry&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/gG9gBIc.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.4 -Fixing topology issues with &lt;code&gt;Fix Geometry&lt;/code&gt; Toolbox&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-3-dissolve-the-layer-on-dn-field&#34;&gt;&lt;strong&gt;Step 3: Dissolve the layer on DN field&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In this step we dissolve the layer based on the &lt;code&gt;DN&lt;/code&gt; value. This will ensure that each polygon can be evaluated based on the land class type which is needed for stratified random sampling.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/gm1ihfT.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.5 -&lt;code&gt;Dissolve&lt;/code&gt; toolbox to dissolve polygon on &lt;code&gt; DN &lt;/code&gt; value&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure to select dissolve field as &lt;code&gt;DN&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-4-create-stratified-random-samples&#34;&gt;&lt;strong&gt;Step 4: Create stratified random samples&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Go to &lt;code&gt;Vector-&amp;gt;research tools-&amp;gt; Random Points inside Polygon&lt;/code&gt; and set &lt;code&gt;Sampling Strategy&lt;/code&gt; = &lt;code&gt;Points Density&lt;/code&gt; and &lt;code&gt;Point count or density&lt;/code&gt; = &lt;code&gt;0.001&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note: The value &lt;code&gt;0.001&lt;/code&gt; signify &lt;code&gt;1&lt;/code&gt; point for &lt;code&gt;1/0.001&lt;/code&gt; m2 of area, given that the units is meters.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/1LB6R5L.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.6 - One sample point is generated for each 1000 m2 of area&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-5-extract-raster-values-to-sample-layer&#34;&gt;&lt;strong&gt;Step 5: Extract raster values to sample layer&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;We extract the raster value, which is essentially the land cover class for the classified image. We use &lt;code&gt;Sample Raster Values&lt;/code&gt; function here (&lt;code&gt;Fig.7&lt;/code&gt;). The input layer is the random points we generated earlier and the the raster layer is the classified image. The output adds a new column to the sample points layer with the prediction class of the land-cover (&lt;code&gt;Fig.8&lt;/code&gt;).&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/s2RXNOZ.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.7 -Running &lt;code&gt;Sample Raster Value&lt;/code&gt; to extract Raster values for the input points&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/GG9wgNK.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.8 -The corresponding Attribute Table with Predicted Class &lt;code&gt; PREDICTED_1&lt;/code&gt; for each feature&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-6-ground-truth-labelling-using-bing-maps&#34;&gt;&lt;strong&gt;Step 6: Ground Truth Labelling using Bing maps&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;At this stage we are ready to validate the image using Bing maps as ground truth. We turn on the edit mode and create new field named Actual class. THen we visually inspect the class on the map and note the land-cover class. Once we inspect all the sample points we can use cohens Kappa statistics to determine the validation result. Alternatively, simply calculating the accuracy would also suffice the need.&lt;/p&gt;
&lt;h2 id=&#34;step-7-add-other-field-to-the-attribute-table-with-reclassification&#34;&gt;&lt;strong&gt;Step 7: Add other field to the attribute table with reclassification&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;We can use the &lt;code&gt;Field Calculator&lt;/code&gt; to generate verbose text for each label in our feature class and display labels for the prediction.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- in field calculator to increase verbosity
CASE WHEN PREDICTED_1 is 2 THEN &#39;Urban&#39; 
WHEN PREDICTED_1 is 1 THEN &#39;Bareland&#39;
WHEN PREDICTED_1 is 4 THEN &#39;Forest&#39;
WHEN PREDICTED_1 is 3 THEN &#39;Urban&#39;
END
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/3CBAK6X.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.9 -Predicted classes (foreground) vs ground truth (background)&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;With this we come to end of the post. Now, validation accuracy can be reported for k-means classification.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
