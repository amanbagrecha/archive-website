<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python | Aman Bagrecha</title>
    <link>https://amanbagrecha.github.io/tag/python/</link>
      <atom:link href="https://amanbagrecha.github.io/tag/python/index.xml" rel="self" type="application/rss+xml" />
    <description>Python</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 07 Feb 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://amanbagrecha.github.io/media/icon_hub8f2c4a40c112e5edee4297ae1d00aa4_198578_512x512_fill_lanczos_center_2.png</url>
      <title>Python</title>
      <link>https://amanbagrecha.github.io/tag/python/</link>
    </image>
    
    <item>
      <title>How to save Earth Engine Image directly to your local machine</title>
      <link>https://amanbagrecha.github.io/post/rs_gis/how-to-save-earth-engine-image-directly-to-your-local-machine/</link>
      <pubDate>Mon, 07 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://amanbagrecha.github.io/post/rs_gis/how-to-save-earth-engine-image-directly-to-your-local-machine/</guid>
      <description>&lt;p&gt;Oftentimes you are required to download satellite images for your Area of Interest (AOI) and Google Earth Engine is probably a good place to avail processed satellite images for free and more importantly, only for the area you need.&lt;/p&gt;
&lt;p&gt;One hindrance when you download from earth engine is that the images get saved in google drive, which can fill up fast for large numbers of downloads. To avoid this additional step, there is a hacky trick to download images directly.&lt;/p&gt;
&lt;p&gt;Note: Earth Engine does provide getDownloadURL option, but is limited in the size of download and thus not feasible in this case. Pixel grid dimensions for &lt;a href=&#34;https://developers.google.com/earth-engine/apidocs/ee-image-getdownloadurl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;getDownloadURL&lt;/a&gt; must be less than or equal to 10000 i.e, you can have a maximum of 100 x 100 pixel size images.&lt;/p&gt;
&lt;p&gt;In this post I show a trick which can let you download upto 100 times larger size images, directly to your local machine. Spoiler: &lt;a href=&#34;https://developers.google.com/earth-engine/apidocs/ee-imagecollection-getregion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;getRegion&lt;/a&gt; method plays a significant role to help accomplish this task. Added to that, creating a gridded bounding box for our AOI, with spacing equivalent to the pixel size will aid in our task.&lt;/p&gt;
&lt;p&gt;We will utilize earth engine python client so that all the geopython goodies can be simultaneously utilised.&lt;/p&gt;
&lt;p&gt;To begin with, I have a geopackage containing a polygon, which is our AOI. We aim to download sentinel-2 B4 band for the region. The ideal way would be to use the in-built &lt;code&gt;Export&lt;/code&gt; option, but in our case we would use the &lt;a href=&#34;https://developers.google.com/earth-engine/apidocs/ee-imagecollection-getregion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;getRegion&lt;/a&gt; method along with creating a point grid over our AOI with spacing equivalent to the pixel size.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/IA5OTuN.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.1 -Left: Our Area of Interest over which to download satellite data. Right: Grid points over AOI bounding box at pixel spacing&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;To accomplish creation of points at spacing equal to pixel width and height, we use the following function&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# generate points
def xcor(y_pt, crs):
    def wrap(x_each):
        feat = ee.FeatureCollection(y_pt.map(lambda y_each: ee.Feature(
            ee.Geometry.Point([x_each, y_each], ee.Projection(crs)))))
        return feat
    return wrap
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code can be interpreted as a nested loop.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Pseudo code
for each_x in x_pt:
    for each_y in y_pt:
        create_Point(each_x, each_y)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;x_pt and y_pt are generated from the geopackage (AOI) using GeoPandas library as follows&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def generatePoints(file_name, pixel_size):

    # read the farm and convert to geojson
    feature = gpd.read_file(file_name).__geo_interface__
    # extract bounds
    minx, miny, maxx, maxy = feature[&#39;bbox&#39;]
    # create a list with spacing equal to pixel_size
    x_pt = ee.List.sequence(minx, maxx, pixel_size)
    y_pt = ee.List.sequence(miny, maxy, pixel_size)
   
    return x_pt, y_pt, minx, maxy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we are basically creating a new &lt;code&gt;Point&lt;/code&gt; feature for each x and y point.&lt;/p&gt;
&lt;p&gt;Once we have the grid over our AOI, we can go ahead and call &lt;code&gt;getRegion&lt;/code&gt; method&lt;/p&gt;
&lt;p&gt;The documentation does a good job in explaining what &lt;code&gt;getRegion&lt;/code&gt; is all about&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Output an array of values for each [pixel, band, image] tuple in an ImageCollection. The output contains rows of id, lon, lat, time, and all bands for each image that intersects each pixel in the given region. Attempting to extract more than 1048576 values will result in an error.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The limit 1048576 results in a max tile width and height of 1024 x 1024 pixels. By combining the previously created grid and &lt;code&gt;getRegion&lt;/code&gt;, we could potentially get 100 times more pixels than getDownloadURL. Let us do that!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;len_y = len(y_pt.getInfo())
len_x = len(x_pt.getInfo())

imgCollection = ee.ImageCollection(&amp;quot;COPERNICUS/S2_SR&amp;quot;).filters(filters_to_add)
geometry = ee.FeatureCollection(x_pt.map(xcor(y_pt, CRS))).flatten()
input_bands = &amp;quot;B4&amp;quot;
pixel_size = 10

df = get_dataframe(imgCollection, geometry, input_bands, CRS )
data_matrix = df[input_bands].values.reshape(len_y, len_x)
data_matrix = np.flip(data_matrix, axis = 0)
transform = rasterio.transform.from_origin(minx, maxy, pixel_size, pixel_size)
save_tiff(&amp;quot;output.tif&amp;quot;, data_matrix, transform, CRS)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code first gets the count of points in each of the 2-dimensions followed by fetching the dataframe which contains the lat, lon and pixel value as shown in the image.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/5SjjW0E.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.2 -Output of getRegion results in lat, lon, pixel value in sequential order&lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Now we reshape the dataframe and flip it to make the pixel arrange in image format. Lastly, we save the image by passing the transformation of the image. Make sure to have an imageCollection for the &lt;code&gt;getRegion&lt;/code&gt; method to work. Currently, the above code can only download 1 band at a time, but with simple modification to the &lt;code&gt;getDataframe&lt;/code&gt; function, that too can be changed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def getDataframe(img_col, feature, input_band, crs):
   
    imgcol = ee.ImageCollection(img_col).select(input_band)
    df = pd.DataFrame(imgcol.[getRegion](https://developers.google.com/earth-engine/apidocs/ee-imagecollection-getregion)(feature.geometry(), 10, crs).getInfo())
    df, df.columns = df[1:], df.iloc[0]
    df = df.drop([&amp;quot;id&amp;quot;, &amp;quot;time&amp;quot;], axis=1)

    return df

def saveTiff(output_name, data_array, transform, crs):

    options = {
        &amp;quot;driver&amp;quot;: &amp;quot;Gtiff&amp;quot;,
        &amp;quot;height&amp;quot;: data_array.shape[0],
        &amp;quot;width&amp;quot;: data_array.shape[1],
        &amp;quot;count&amp;quot;: 1,
        &amp;quot;dtype&amp;quot;: np.float32,
        &amp;quot;crs&amp;quot;: crs,
        &amp;quot;transform&amp;quot;: transform
    }

    with rs.open(output_name, &#39;w&#39;, **options) as src:
        src.write(data_array, 1)

    return None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of the exercise is that you have a raster directly downloaded to your local machine, without google drive/ cloud intermediaries. One thing worth pointing out, is for extremely large images, you are better off downloading via the specified steps in docs. This hacky way is to simplify things and avoid google drive (which is never empty for me).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Z8DEJHh.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The full code can be accessed &lt;a href=&#34;https://github.com/amanbagrecha/ee-image-direct-download&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Polygonize Raster and Compute Zonal-Statistics in Python</title>
      <link>https://amanbagrecha.github.io/post/rs_gis/polygonize-raster-and-compute-zonal-stats-in-python/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://amanbagrecha.github.io/post/rs_gis/polygonize-raster-and-compute-zonal-stats-in-python/</guid>
      <description>&lt;p&gt;The output of a clustering algorithm is a raster. But when you want to compute statistics of the clustered raster, it needs to be polygonized.&lt;/p&gt;
&lt;p&gt;A simple way to perform this action is using the gdal command line &lt;code&gt;gdal_polygonize.py&lt;/code&gt; script. This script requires the output file format, input raster file and output name of the vector file. You can additionally mask pixel values which you don&amp;rsquo;t want to convert to polygons. For this example, we would consider a single band image.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python gdal_polygonize.py raster_file -f &amp;quot;ESRI Shapefile&amp;quot; vector_file.shp  layername atrributefieldname
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;--nomask&lt;/code&gt; allows to include nodata values in the shapefile&lt;/p&gt;
&lt;p&gt;&lt;code&gt;atrributefieldname&lt;/code&gt; should always be preceded with &lt;code&gt;layername&lt;/code&gt; else it would result in an error.&lt;/p&gt;
&lt;p&gt;The output would result in a vector layer. The number of output polygons is equal to the number of non-NA values. Each neighbouring cell (pixel) which is connected in the raster having the same value is combined to form a single polygon.&lt;/p&gt;
&lt;p&gt;For instance, consider this 4 x 4 raster. When converted to vector, it resulted in 6 polygons. Note that disconnected similar values form an independent polygon. Each polygon will have an attribute as its pixel value from the raster, in the data type of the image. These would end up being a pair of (polygon, value) for each feature found in the image.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/xeJ4BGa.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.1 -Converting Raster to Vector using GDAL. The output polygon has attribute associated with its raster value &lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Another way to polygonize raster programmatically is to use the &lt;code&gt;rasterio&lt;/code&gt; library. Since rasterio utilizes GDAL under the hood, it also performs similar action and results in a pair of geometry and raster value. We create a tuple of dictionaries to store each feature output.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# code to polygonize using rasterio
from rasterio import features

# read the raster and polygonize
with rasterio.open(cluster_image_path) as src:
    image = src.read(1, out_dtype=&#39;uint16&#39;) 
    #Make a mask!
    mask = image != 0
# `results` contains a tuple. With each element in the tuple representing a dictionary containing the feature (polygon) and its associated raster value
results = ( {&#39;properties&#39;: {&#39;cluster_id&#39;: int(v)}, &#39;geometry&#39;: s} 
            for (s, v) in (features.shapes(image, mask=mask, transform=src.transform)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have the raster polygonized, we can use &lt;code&gt;rasterstats&lt;/code&gt; library to calculate zonal statistics. We use this library since there is no in-built functionality for rasterio to calculate it.&lt;/p&gt;
&lt;p&gt;This library has a function &lt;code&gt;zonal_stats&lt;/code&gt; which takes in a vector layer and a raster to calculate the zonal statistics. Read more &lt;a href=&#34;https://pythonhosted.org/rasterstats/manual.html#zonal-statistics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The parameters to the function are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;vectors: path to an vector source or geo-like python objects&lt;/li&gt;
&lt;li&gt;raster: ndarray or path to a GDAL raster source&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;and various other options which can be found &lt;a href=&#34;https://github.com/perrygeo/python-rasterstats/blob/master/src/rasterstats/main.py#L34&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To create a vector layer from the tuple &lt;code&gt;results&lt;/code&gt;, we use geopandas. There are other libraries (such as fiona) which can also create vector geometry from shapely objects.&lt;/p&gt;
&lt;p&gt;For raster, we pass the &lt;code&gt;.tif&lt;/code&gt; file directly to &lt;code&gt;zonal_stats&lt;/code&gt;. The final code looks like the following&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from rasterstats import zonal_stats

in_shp = gpd.GeoDataFrame.from_features(results).set_crs(crs=src.crs)

# stats parameter takes in various statistics that needs to be computed 
statistics= zonal_stats(in_shp,image,stats=&#39;min, max, mean, median&#39;,
                geojson_out=True, nodata = -999)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output is a geojson generator when &lt;code&gt;geojson_out&lt;/code&gt; is True. we can convert the geojson to dataframe and export as csv for further processing.&lt;/p&gt;
&lt;p&gt;This way, with the help of geopandas, rasterstats and rasterio, we polygonize the raster and calculate zonal statistics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Three ways to Programmatically change projection of raw CSV</title>
      <link>https://amanbagrecha.github.io/post/rs_gis/three-ways-to-change-projection-of-raw-csv/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://amanbagrecha.github.io/post/rs_gis/three-ways-to-change-projection-of-raw-csv/</guid>
      <description>&lt;p&gt;Often, field values are collected in the Geographic Coordinate System as ASCII or CSV so that it can be universally used. But when you want to perform any kind of analysis on these points, there is a need to reproject them into a Projected Coordinate Reference System for the specific area. Although there are many ways that exist now with desktop GIS, these methods can be cumbersome if you have thousands of files to reproject.&lt;/p&gt;
&lt;p&gt;This task of reprojecting raw CSV can be accomplished using GDAL although it is not straightforward. It requires an indication of geographic data of a CSV file which is provided using VRT (GDAL virtual Raster). More advanced tools now exist which are either built on top of GDAL or are very similar. pyproj and GeoPandas are two such libraries which can help us reproject our raw CSV on-the-fly.&lt;/p&gt;
&lt;p&gt;We first look at how this task can be accomplished using the GDAL command line.&lt;/p&gt;
&lt;h3 id=&#34;reproject-csv-using-ogr2ogr&#34;&gt;Reproject CSV using ogr2ogr&lt;/h3&gt;
&lt;p&gt;This example shows using ogr2ogr to reproject the Coordinate Reference System of a CSV file with the longitude, latitude coordinates stored as columns in the &lt;code&gt;.csv&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ogr2ogr -f CSV -lco GEOMETRY=AS_XY -t_srs EPSG:4326 output.csv input.vrt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;-lco GEOMETRY=AS_XY&lt;/code&gt; : Layer creation option with XY columns added in output csv.&lt;/p&gt;
&lt;p&gt;In the above code, &lt;code&gt;input.vrt&lt;/code&gt; is a GDAL virtual raster which has to be created prior to running the command. It points to the CSV file which has the location data stored as columns (lon, lat)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;!--input.vrt pointing to the filename.csv--&amp;gt;
&amp;lt;OGRVRTDataSource&amp;gt; 
  &amp;lt;OGRVRTLayer name=&amp;quot;layername&amp;quot;&amp;gt; 
    &amp;lt;SrcDataSource&amp;gt;filename.csv&amp;lt;/SrcDataSource&amp;gt; 
    &amp;lt;GeometryType&amp;gt;wkbPoint&amp;lt;/GeometryType&amp;gt; 
    &amp;lt;LayerSRS&amp;gt;EPSG:4326&amp;lt;/LayerSRS&amp;gt; 
    &amp;lt;GeometryField encoding=&amp;quot;PointFromColumns&amp;quot; x=&amp;quot;lon&amp;quot; y=&amp;quot;lat&amp;quot;/&amp;gt; 
  &amp;lt;/OGRVRTLayer&amp;gt; 
&amp;lt;/OGRVRTDataSource&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Why did we create this vrt file?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, VRT is a virtual gdal driver which allows for lazy processing. Often, we have to save intermediary outputs on our local disk, which could potentially take a lot of space. To avoid that, VRT allows to store the processing in an xml encoding and performs all intermediary action at once, in the final step.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;But what does the above xml mean?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The first line &lt;code&gt;&amp;lt;OGRVRTDataSource&amp;gt;&lt;/code&gt; is the root element. &lt;code&gt;&amp;lt;OGRVRTLayer name=&amp;quot;layername&amp;quot;&amp;gt;&lt;/code&gt; corresponds with the &lt;code&gt;&amp;lt;SrcDataSource&amp;gt; filename.csv &amp;lt;/SrcDataSource&amp;gt;&lt;/code&gt; and points to the CSV we want to reproject. &lt;code&gt;&amp;lt;LayerSRS&amp;gt;EPSG:4326&amp;lt;/LayerSRS&amp;gt;&lt;/code&gt; should correspond with the EPSG of the coordinates stored in the CSV file. &lt;code&gt;&amp;lt;GeometryType&amp;gt; wkbPoint &amp;lt;/GeometryType&amp;gt;&lt;/code&gt; is the format that coordinates are stored as. Lastly, &lt;code&gt;&amp;lt;GeometryField encoding=&amp;quot;PointFromColumns&amp;quot; x=&amp;quot;lon&amp;quot; y=&amp;quot;lat&amp;quot;/&amp;gt;&lt;/code&gt; indicates the columns corresponding to lon and lat in csv.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/HefHXvu.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;Fig.1 -Reprojecting CSV from EPSG:4326 to EPSG:32644 &lt;/i&gt;&lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Hence, by running the above GDAL command, we would be able to reproject our csv. By writing a bash script, this method can be scaled to thousands of files. But the intermediary &lt;code&gt;.vrt&lt;/code&gt; file is messy to handle and it would be nice to avoid it. Luckily for us, there are high-level libraries in python which would avoid such hassle.&lt;/p&gt;
&lt;h2 id=&#34;using-geopandas&#34;&gt;Using GeoPandas&lt;/h2&gt;
&lt;p&gt;The modern geospatial libraries are &lt;em&gt;low code tools&lt;/em&gt;. One such excellent library is GeoPandas, which is built on top of fiona, which in-turn is built on top of GDAL. Geopandas allows us to read, project and modify files on-the-fly. Additionally, the ability to create geometry from &lt;code&gt;lat, lon&lt;/code&gt; allows us to pass our CSV files and modify its CRS.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;in_path = &#39;./&#39;
out_path = &#39;./output&#39;
files= [f for f in os.listdir(in_path) if f.endswith(&#39;.csv&#39;)]
input_crs = &#39;EPSG:4326&#39;
output_crs = &#39;EPSG:32644&#39;

if not os.path.exists(out_path):
    os.mkdir(out_path)

for file in files:
    df = pd.read_csv(file, header=None)
    gdf = gpd.GeoDataFrame(
        df, crs=input_crs , geometry=gpd.points_from_xy(df.iloc[:,0], df.iloc[:,1]))

    gdf.to_crs(output_crs, inplace=True)
    gdf.iloc[:,0] = gdf.geometry.x # replace x
    gdf.iloc[:,1] = gdf.geometry.y # replace y
    
    # export reprojected csv 
    gdf.iloc[:,:-1].to_csv(os.path.join(out_path, file), index=False )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above code, we loop through our CSV files. For each file, we create a geodataframe and change the CRS. Lastly, we replace the coordinates with reprojected one.&lt;/p&gt;
&lt;p&gt;There is another way using pyproj library which does this exact thing, but geopandas is more intuitive for me personally.&lt;/p&gt;
&lt;p&gt;To read about the pyproj method, refer &lt;a href=&#34;https://gis.stackexchange.com/a/168496&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;endnote&#34;&gt;EndNote&lt;/h2&gt;
&lt;p&gt;Although there are several other ways to reproject raw CSV, I found these to be concise and efficient. Thanks to &lt;a href=&#34;https://gis.stackexchange.com/&#34;&gt;https://gis.stackexchange.com/&lt;/a&gt; and awesome GIS community, these methods work like a charm 😊&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SMAP Soil Moisture Time Series Analysis</title>
      <link>https://amanbagrecha.github.io/project/smap-soil-moisture/</link>
      <pubDate>Wed, 08 Sep 2021 14:15:36 +0530</pubDate>
      <guid>https://amanbagrecha.github.io/project/smap-soil-moisture/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Predicting Age group of Social Media Application users</title>
      <link>https://amanbagrecha.github.io/project/ml_challenge/</link>
      <pubDate>Sat, 24 Jul 2021 19:56:56 +0530</pubDate>
      <guid>https://amanbagrecha.github.io/project/ml_challenge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Analyse professional degree student enrolment v/s university count</title>
      <link>https://amanbagrecha.github.io/project/enrolmentbylevel/</link>
      <pubDate>Mon, 12 Jul 2021 19:56:56 +0530</pubDate>
      <guid>https://amanbagrecha.github.io/project/enrolmentbylevel/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Radiant Earth Spot the Crop Hackathon</title>
      <link>https://amanbagrecha.github.io/project/spot-the-crop-radiantearth/</link>
      <pubDate>Mon, 12 Jul 2021 19:56:56 +0530</pubDate>
      <guid>https://amanbagrecha.github.io/project/spot-the-crop-radiantearth/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Django-rest-framework CRUD Token Authetication Application</title>
      <link>https://amanbagrecha.github.io/project/external-project/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://amanbagrecha.github.io/project/external-project/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
